{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing - check if Standard Sxcaler will work well\n",
    "# Alternatively, divide by 200?\n",
    "# source: https://medium.com/analytics-vidhya/introduction-to-neural-networks-for-finance-6abd5675e497"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7106, 56)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "camel_data = pd.read_csv('data/camel_data_timeseries.csv', index_col = 0)\n",
    "camel_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EQTA</th>\n",
       "      <th>EQTL</th>\n",
       "      <th>LLRTA</th>\n",
       "      <th>LLRGL</th>\n",
       "      <th>OEXTA</th>\n",
       "      <th>INCEMP</th>\n",
       "      <th>ROA</th>\n",
       "      <th>ROE</th>\n",
       "      <th>TDTL</th>\n",
       "      <th>TDTA</th>\n",
       "      <th>...</th>\n",
       "      <th>LLRTA-4Q</th>\n",
       "      <th>LLRGL-4Q</th>\n",
       "      <th>OEXTA-4Q</th>\n",
       "      <th>INCEMP-4Q</th>\n",
       "      <th>ROA-4Q</th>\n",
       "      <th>ROE-4Q</th>\n",
       "      <th>TDTL-4Q</th>\n",
       "      <th>TDTA-4Q</th>\n",
       "      <th>TATA-4Q</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.212297</td>\n",
       "      <td>0.390905</td>\n",
       "      <td>0.010553</td>\n",
       "      <td>0.019431</td>\n",
       "      <td>0.021300</td>\n",
       "      <td>22.347826</td>\n",
       "      <td>0.006235</td>\n",
       "      <td>0.029368</td>\n",
       "      <td>1.438278</td>\n",
       "      <td>0.781116</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011724</td>\n",
       "      <td>0.021130</td>\n",
       "      <td>0.028695</td>\n",
       "      <td>24.120000</td>\n",
       "      <td>0.007341</td>\n",
       "      <td>0.036028</td>\n",
       "      <td>1.428885</td>\n",
       "      <td>0.792783</td>\n",
       "      <td>0.373285</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>0.138115</td>\n",
       "      <td>0.208180</td>\n",
       "      <td>0.005476</td>\n",
       "      <td>0.008254</td>\n",
       "      <td>0.020049</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>0.014078</td>\n",
       "      <td>0.101927</td>\n",
       "      <td>1.082964</td>\n",
       "      <td>0.718480</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005004</td>\n",
       "      <td>0.007882</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>39.538462</td>\n",
       "      <td>0.015403</td>\n",
       "      <td>0.120178</td>\n",
       "      <td>1.196574</td>\n",
       "      <td>0.759754</td>\n",
       "      <td>0.257836</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>0.148749</td>\n",
       "      <td>0.309703</td>\n",
       "      <td>0.003029</td>\n",
       "      <td>0.006306</td>\n",
       "      <td>0.020605</td>\n",
       "      <td>17.475000</td>\n",
       "      <td>0.004466</td>\n",
       "      <td>0.030024</td>\n",
       "      <td>1.388137</td>\n",
       "      <td>0.666716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003401</td>\n",
       "      <td>0.007432</td>\n",
       "      <td>0.026377</td>\n",
       "      <td>9.475000</td>\n",
       "      <td>0.002446</td>\n",
       "      <td>0.016889</td>\n",
       "      <td>1.389068</td>\n",
       "      <td>0.635692</td>\n",
       "      <td>0.145053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>0.107925</td>\n",
       "      <td>0.244104</td>\n",
       "      <td>0.022419</td>\n",
       "      <td>0.050708</td>\n",
       "      <td>0.025443</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>0.001147</td>\n",
       "      <td>0.010628</td>\n",
       "      <td>2.014151</td>\n",
       "      <td>0.890511</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022978</td>\n",
       "      <td>0.044882</td>\n",
       "      <td>0.041032</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>0.003048</td>\n",
       "      <td>0.025794</td>\n",
       "      <td>1.658118</td>\n",
       "      <td>0.848886</td>\n",
       "      <td>0.447362</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>0.083266</td>\n",
       "      <td>0.105280</td>\n",
       "      <td>0.010631</td>\n",
       "      <td>0.013441</td>\n",
       "      <td>0.017548</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>0.010071</td>\n",
       "      <td>0.120953</td>\n",
       "      <td>1.007846</td>\n",
       "      <td>0.797101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012244</td>\n",
       "      <td>0.013760</td>\n",
       "      <td>0.025836</td>\n",
       "      <td>35.333333</td>\n",
       "      <td>0.008930</td>\n",
       "      <td>0.097997</td>\n",
       "      <td>0.906047</td>\n",
       "      <td>0.806229</td>\n",
       "      <td>0.014350</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.077013</td>\n",
       "      <td>0.122921</td>\n",
       "      <td>0.011596</td>\n",
       "      <td>0.018508</td>\n",
       "      <td>0.020537</td>\n",
       "      <td>18.592593</td>\n",
       "      <td>0.005170</td>\n",
       "      <td>0.067128</td>\n",
       "      <td>1.272360</td>\n",
       "      <td>0.797165</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011893</td>\n",
       "      <td>0.017178</td>\n",
       "      <td>0.031016</td>\n",
       "      <td>22.845455</td>\n",
       "      <td>0.006874</td>\n",
       "      <td>0.089798</td>\n",
       "      <td>1.142031</td>\n",
       "      <td>0.790691</td>\n",
       "      <td>0.199013</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155</th>\n",
       "      <td>0.098782</td>\n",
       "      <td>0.133240</td>\n",
       "      <td>0.010796</td>\n",
       "      <td>0.014562</td>\n",
       "      <td>0.021385</td>\n",
       "      <td>31.821429</td>\n",
       "      <td>0.009028</td>\n",
       "      <td>0.091394</td>\n",
       "      <td>1.130753</td>\n",
       "      <td>0.838320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>0.014763</td>\n",
       "      <td>0.024293</td>\n",
       "      <td>50.980769</td>\n",
       "      <td>0.011771</td>\n",
       "      <td>0.155548</td>\n",
       "      <td>1.305846</td>\n",
       "      <td>0.866845</td>\n",
       "      <td>0.133354</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1351</th>\n",
       "      <td>0.137449</td>\n",
       "      <td>0.282032</td>\n",
       "      <td>0.009761</td>\n",
       "      <td>0.020028</td>\n",
       "      <td>0.012637</td>\n",
       "      <td>53.724138</td>\n",
       "      <td>0.010620</td>\n",
       "      <td>0.077263</td>\n",
       "      <td>1.760402</td>\n",
       "      <td>0.857936</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008064</td>\n",
       "      <td>0.015834</td>\n",
       "      <td>0.017072</td>\n",
       "      <td>94.678571</td>\n",
       "      <td>0.019088</td>\n",
       "      <td>0.137052</td>\n",
       "      <td>1.682010</td>\n",
       "      <td>0.856658</td>\n",
       "      <td>0.026986</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>0.106132</td>\n",
       "      <td>0.239352</td>\n",
       "      <td>0.006746</td>\n",
       "      <td>0.015214</td>\n",
       "      <td>0.023092</td>\n",
       "      <td>45.738255</td>\n",
       "      <td>0.013856</td>\n",
       "      <td>0.130553</td>\n",
       "      <td>2.010991</td>\n",
       "      <td>0.891697</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006391</td>\n",
       "      <td>0.014072</td>\n",
       "      <td>0.034547</td>\n",
       "      <td>48.530201</td>\n",
       "      <td>0.015703</td>\n",
       "      <td>0.159154</td>\n",
       "      <td>1.978913</td>\n",
       "      <td>0.898765</td>\n",
       "      <td>0.430634</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1557</th>\n",
       "      <td>0.096508</td>\n",
       "      <td>0.170844</td>\n",
       "      <td>0.006890</td>\n",
       "      <td>0.012196</td>\n",
       "      <td>0.014719</td>\n",
       "      <td>36.750000</td>\n",
       "      <td>0.007975</td>\n",
       "      <td>0.082631</td>\n",
       "      <td>1.518262</td>\n",
       "      <td>0.857652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008291</td>\n",
       "      <td>0.013245</td>\n",
       "      <td>0.022451</td>\n",
       "      <td>47.727273</td>\n",
       "      <td>0.011454</td>\n",
       "      <td>0.103693</td>\n",
       "      <td>1.332381</td>\n",
       "      <td>0.834010</td>\n",
       "      <td>0.110638</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1669</th>\n",
       "      <td>0.182143</td>\n",
       "      <td>0.539039</td>\n",
       "      <td>0.008249</td>\n",
       "      <td>0.024414</td>\n",
       "      <td>0.014856</td>\n",
       "      <td>47.122807</td>\n",
       "      <td>0.010788</td>\n",
       "      <td>0.059227</td>\n",
       "      <td>2.410124</td>\n",
       "      <td>0.814387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007971</td>\n",
       "      <td>0.024153</td>\n",
       "      <td>0.020969</td>\n",
       "      <td>52.152542</td>\n",
       "      <td>0.012546</td>\n",
       "      <td>0.073255</td>\n",
       "      <td>2.496510</td>\n",
       "      <td>0.823894</td>\n",
       "      <td>0.147797</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1829</th>\n",
       "      <td>0.101380</td>\n",
       "      <td>0.175248</td>\n",
       "      <td>0.009586</td>\n",
       "      <td>0.016571</td>\n",
       "      <td>0.019664</td>\n",
       "      <td>27.076087</td>\n",
       "      <td>0.006001</td>\n",
       "      <td>0.059195</td>\n",
       "      <td>1.380148</td>\n",
       "      <td>0.798408</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010035</td>\n",
       "      <td>0.017037</td>\n",
       "      <td>0.027167</td>\n",
       "      <td>29.031915</td>\n",
       "      <td>0.006645</td>\n",
       "      <td>0.067266</td>\n",
       "      <td>1.360503</td>\n",
       "      <td>0.801319</td>\n",
       "      <td>0.191627</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1856</th>\n",
       "      <td>0.121966</td>\n",
       "      <td>0.695801</td>\n",
       "      <td>0.001157</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>0.008081</td>\n",
       "      <td>34.125000</td>\n",
       "      <td>0.001564</td>\n",
       "      <td>0.012820</td>\n",
       "      <td>3.238196</td>\n",
       "      <td>0.567618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>0.018165</td>\n",
       "      <td>0.009791</td>\n",
       "      <td>371.000000</td>\n",
       "      <td>0.017125</td>\n",
       "      <td>0.221993</td>\n",
       "      <td>9.922287</td>\n",
       "      <td>0.644366</td>\n",
       "      <td>0.449337</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2040</th>\n",
       "      <td>0.097353</td>\n",
       "      <td>0.131587</td>\n",
       "      <td>0.016861</td>\n",
       "      <td>0.022790</td>\n",
       "      <td>0.019106</td>\n",
       "      <td>19.347826</td>\n",
       "      <td>0.004296</td>\n",
       "      <td>0.044129</td>\n",
       "      <td>1.058551</td>\n",
       "      <td>0.783156</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013091</td>\n",
       "      <td>0.018169</td>\n",
       "      <td>0.022769</td>\n",
       "      <td>37.521739</td>\n",
       "      <td>0.007802</td>\n",
       "      <td>0.092448</td>\n",
       "      <td>1.090574</td>\n",
       "      <td>0.785773</td>\n",
       "      <td>0.207786</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2161</th>\n",
       "      <td>0.111464</td>\n",
       "      <td>0.231983</td>\n",
       "      <td>0.004719</td>\n",
       "      <td>0.009820</td>\n",
       "      <td>0.021137</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>0.014565</td>\n",
       "      <td>0.130670</td>\n",
       "      <td>1.816885</td>\n",
       "      <td>0.872984</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004525</td>\n",
       "      <td>0.009406</td>\n",
       "      <td>0.028190</td>\n",
       "      <td>63.437500</td>\n",
       "      <td>0.016346</td>\n",
       "      <td>0.160284</td>\n",
       "      <td>1.839523</td>\n",
       "      <td>0.884976</td>\n",
       "      <td>0.344969</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2376</th>\n",
       "      <td>0.163295</td>\n",
       "      <td>0.261252</td>\n",
       "      <td>0.011117</td>\n",
       "      <td>0.017786</td>\n",
       "      <td>0.014525</td>\n",
       "      <td>38.883978</td>\n",
       "      <td>0.002897</td>\n",
       "      <td>0.017741</td>\n",
       "      <td>0.850152</td>\n",
       "      <td>0.531386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011218</td>\n",
       "      <td>0.016716</td>\n",
       "      <td>0.014932</td>\n",
       "      <td>54.598870</td>\n",
       "      <td>0.004891</td>\n",
       "      <td>0.049744</td>\n",
       "      <td>0.923529</td>\n",
       "      <td>0.619765</td>\n",
       "      <td>0.211138</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2554</th>\n",
       "      <td>0.111775</td>\n",
       "      <td>0.199361</td>\n",
       "      <td>0.008261</td>\n",
       "      <td>0.014735</td>\n",
       "      <td>0.019110</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.009157</td>\n",
       "      <td>0.081923</td>\n",
       "      <td>1.512871</td>\n",
       "      <td>0.848213</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006750</td>\n",
       "      <td>0.012025</td>\n",
       "      <td>0.025362</td>\n",
       "      <td>31.750000</td>\n",
       "      <td>0.012247</td>\n",
       "      <td>0.112489</td>\n",
       "      <td>1.582374</td>\n",
       "      <td>0.888235</td>\n",
       "      <td>0.001157</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>0.139267</td>\n",
       "      <td>0.183945</td>\n",
       "      <td>0.008706</td>\n",
       "      <td>0.011498</td>\n",
       "      <td>0.017158</td>\n",
       "      <td>22.790000</td>\n",
       "      <td>0.004304</td>\n",
       "      <td>0.030902</td>\n",
       "      <td>1.129128</td>\n",
       "      <td>0.854877</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008571</td>\n",
       "      <td>0.010788</td>\n",
       "      <td>0.022737</td>\n",
       "      <td>24.250000</td>\n",
       "      <td>0.004614</td>\n",
       "      <td>0.033576</td>\n",
       "      <td>1.078822</td>\n",
       "      <td>0.857105</td>\n",
       "      <td>0.112309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2750</th>\n",
       "      <td>0.097927</td>\n",
       "      <td>0.143254</td>\n",
       "      <td>0.010779</td>\n",
       "      <td>0.015768</td>\n",
       "      <td>0.017180</td>\n",
       "      <td>35.909091</td>\n",
       "      <td>0.006946</td>\n",
       "      <td>0.070928</td>\n",
       "      <td>1.137723</td>\n",
       "      <td>0.777735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009461</td>\n",
       "      <td>0.012816</td>\n",
       "      <td>0.025072</td>\n",
       "      <td>35.909091</td>\n",
       "      <td>0.007187</td>\n",
       "      <td>0.075874</td>\n",
       "      <td>1.088211</td>\n",
       "      <td>0.803319</td>\n",
       "      <td>0.214676</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3252</th>\n",
       "      <td>0.120849</td>\n",
       "      <td>0.256903</td>\n",
       "      <td>0.008299</td>\n",
       "      <td>0.017642</td>\n",
       "      <td>0.014164</td>\n",
       "      <td>76.764706</td>\n",
       "      <td>0.016585</td>\n",
       "      <td>0.137238</td>\n",
       "      <td>1.816704</td>\n",
       "      <td>0.854591</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007178</td>\n",
       "      <td>0.015256</td>\n",
       "      <td>0.022715</td>\n",
       "      <td>88.558824</td>\n",
       "      <td>0.019847</td>\n",
       "      <td>0.172709</td>\n",
       "      <td>1.826539</td>\n",
       "      <td>0.859422</td>\n",
       "      <td>0.433962</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3458</th>\n",
       "      <td>0.101578</td>\n",
       "      <td>0.221555</td>\n",
       "      <td>0.009057</td>\n",
       "      <td>0.019754</td>\n",
       "      <td>0.016418</td>\n",
       "      <td>12.636364</td>\n",
       "      <td>0.004448</td>\n",
       "      <td>0.043793</td>\n",
       "      <td>1.746056</td>\n",
       "      <td>0.800525</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009207</td>\n",
       "      <td>0.020592</td>\n",
       "      <td>0.029546</td>\n",
       "      <td>-62.090909</td>\n",
       "      <td>-0.023910</td>\n",
       "      <td>-0.228887</td>\n",
       "      <td>1.809270</td>\n",
       "      <td>0.808934</td>\n",
       "      <td>0.262550</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3720</th>\n",
       "      <td>0.143787</td>\n",
       "      <td>0.241168</td>\n",
       "      <td>0.007816</td>\n",
       "      <td>0.013109</td>\n",
       "      <td>0.023006</td>\n",
       "      <td>30.637931</td>\n",
       "      <td>0.009229</td>\n",
       "      <td>0.064182</td>\n",
       "      <td>1.344805</td>\n",
       "      <td>0.801792</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008663</td>\n",
       "      <td>0.015367</td>\n",
       "      <td>0.031594</td>\n",
       "      <td>31.842105</td>\n",
       "      <td>0.009581</td>\n",
       "      <td>0.069969</td>\n",
       "      <td>1.446861</td>\n",
       "      <td>0.815599</td>\n",
       "      <td>0.206984</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953</th>\n",
       "      <td>0.069926</td>\n",
       "      <td>0.074322</td>\n",
       "      <td>0.022649</td>\n",
       "      <td>0.024073</td>\n",
       "      <td>0.029820</td>\n",
       "      <td>-27.894737</td>\n",
       "      <td>-0.008778</td>\n",
       "      <td>-0.125533</td>\n",
       "      <td>0.910723</td>\n",
       "      <td>0.856845</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015320</td>\n",
       "      <td>0.016101</td>\n",
       "      <td>0.036605</td>\n",
       "      <td>29.368421</td>\n",
       "      <td>0.008854</td>\n",
       "      <td>0.113024</td>\n",
       "      <td>0.867616</td>\n",
       "      <td>0.825517</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4138</th>\n",
       "      <td>0.090290</td>\n",
       "      <td>0.132076</td>\n",
       "      <td>0.016210</td>\n",
       "      <td>0.023712</td>\n",
       "      <td>0.032817</td>\n",
       "      <td>-11.929825</td>\n",
       "      <td>-0.003798</td>\n",
       "      <td>-0.042069</td>\n",
       "      <td>1.302556</td>\n",
       "      <td>0.890455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014759</td>\n",
       "      <td>0.021005</td>\n",
       "      <td>0.038339</td>\n",
       "      <td>-2.283582</td>\n",
       "      <td>-0.000816</td>\n",
       "      <td>-0.009446</td>\n",
       "      <td>1.275345</td>\n",
       "      <td>0.896120</td>\n",
       "      <td>0.171738</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4156</th>\n",
       "      <td>0.102335</td>\n",
       "      <td>0.136832</td>\n",
       "      <td>0.011378</td>\n",
       "      <td>0.015214</td>\n",
       "      <td>0.024893</td>\n",
       "      <td>22.983051</td>\n",
       "      <td>0.007244</td>\n",
       "      <td>0.070784</td>\n",
       "      <td>0.980858</td>\n",
       "      <td>0.733576</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012397</td>\n",
       "      <td>0.017842</td>\n",
       "      <td>0.034520</td>\n",
       "      <td>5.176471</td>\n",
       "      <td>0.001719</td>\n",
       "      <td>0.019546</td>\n",
       "      <td>1.127239</td>\n",
       "      <td>0.783229</td>\n",
       "      <td>0.176553</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4231</th>\n",
       "      <td>0.115423</td>\n",
       "      <td>0.175452</td>\n",
       "      <td>0.005928</td>\n",
       "      <td>0.009011</td>\n",
       "      <td>0.018150</td>\n",
       "      <td>8.212121</td>\n",
       "      <td>0.002114</td>\n",
       "      <td>0.018313</td>\n",
       "      <td>1.332100</td>\n",
       "      <td>0.876333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008918</td>\n",
       "      <td>0.013762</td>\n",
       "      <td>0.023722</td>\n",
       "      <td>7.441176</td>\n",
       "      <td>0.001983</td>\n",
       "      <td>0.017752</td>\n",
       "      <td>1.361838</td>\n",
       "      <td>0.882495</td>\n",
       "      <td>0.225974</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4437</th>\n",
       "      <td>0.098129</td>\n",
       "      <td>0.160124</td>\n",
       "      <td>0.012109</td>\n",
       "      <td>0.019759</td>\n",
       "      <td>0.020315</td>\n",
       "      <td>15.661538</td>\n",
       "      <td>0.003857</td>\n",
       "      <td>0.039305</td>\n",
       "      <td>1.414022</td>\n",
       "      <td>0.866563</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012017</td>\n",
       "      <td>0.017486</td>\n",
       "      <td>0.025459</td>\n",
       "      <td>17.126984</td>\n",
       "      <td>0.004191</td>\n",
       "      <td>0.044785</td>\n",
       "      <td>1.233140</td>\n",
       "      <td>0.847450</td>\n",
       "      <td>0.219132</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4839</th>\n",
       "      <td>0.100318</td>\n",
       "      <td>0.130596</td>\n",
       "      <td>0.013187</td>\n",
       "      <td>0.017167</td>\n",
       "      <td>0.026015</td>\n",
       "      <td>25.915663</td>\n",
       "      <td>0.006959</td>\n",
       "      <td>0.069371</td>\n",
       "      <td>1.055053</td>\n",
       "      <td>0.810445</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011306</td>\n",
       "      <td>0.014848</td>\n",
       "      <td>0.035159</td>\n",
       "      <td>14.305882</td>\n",
       "      <td>0.003907</td>\n",
       "      <td>0.046640</td>\n",
       "      <td>1.055074</td>\n",
       "      <td>0.803433</td>\n",
       "      <td>0.179947</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5005</th>\n",
       "      <td>0.065712</td>\n",
       "      <td>0.093764</td>\n",
       "      <td>0.006650</td>\n",
       "      <td>0.009489</td>\n",
       "      <td>0.031140</td>\n",
       "      <td>-35.040000</td>\n",
       "      <td>-0.009028</td>\n",
       "      <td>-0.137390</td>\n",
       "      <td>1.109632</td>\n",
       "      <td>0.777649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020428</td>\n",
       "      <td>0.025559</td>\n",
       "      <td>0.036077</td>\n",
       "      <td>-88.644231</td>\n",
       "      <td>-0.021812</td>\n",
       "      <td>-0.330217</td>\n",
       "      <td>0.961760</td>\n",
       "      <td>0.768697</td>\n",
       "      <td>0.136367</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5069</th>\n",
       "      <td>0.225603</td>\n",
       "      <td>0.263607</td>\n",
       "      <td>0.060829</td>\n",
       "      <td>0.071075</td>\n",
       "      <td>0.007864</td>\n",
       "      <td>584.551724</td>\n",
       "      <td>0.034226</td>\n",
       "      <td>0.151709</td>\n",
       "      <td>0.888147</td>\n",
       "      <td>0.760104</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039154</td>\n",
       "      <td>0.043390</td>\n",
       "      <td>0.007395</td>\n",
       "      <td>791.464286</td>\n",
       "      <td>0.044872</td>\n",
       "      <td>0.216833</td>\n",
       "      <td>0.869779</td>\n",
       "      <td>0.784867</td>\n",
       "      <td>0.038237</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3897434</th>\n",
       "      <td>0.169637</td>\n",
       "      <td>0.312125</td>\n",
       "      <td>0.007470</td>\n",
       "      <td>0.013745</td>\n",
       "      <td>0.028984</td>\n",
       "      <td>-62.222222</td>\n",
       "      <td>-0.015212</td>\n",
       "      <td>-0.089672</td>\n",
       "      <td>1.489954</td>\n",
       "      <td>0.809773</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006125</td>\n",
       "      <td>0.014269</td>\n",
       "      <td>0.073571</td>\n",
       "      <td>-269.250000</td>\n",
       "      <td>-0.071320</td>\n",
       "      <td>-0.324691</td>\n",
       "      <td>1.807019</td>\n",
       "      <td>0.775710</td>\n",
       "      <td>0.382889</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3900950</th>\n",
       "      <td>0.137348</td>\n",
       "      <td>0.215121</td>\n",
       "      <td>0.008342</td>\n",
       "      <td>0.013066</td>\n",
       "      <td>0.023643</td>\n",
       "      <td>-9.612903</td>\n",
       "      <td>-0.002625</td>\n",
       "      <td>-0.019112</td>\n",
       "      <td>1.349696</td>\n",
       "      <td>0.861736</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006748</td>\n",
       "      <td>0.013403</td>\n",
       "      <td>0.036561</td>\n",
       "      <td>-47.032258</td>\n",
       "      <td>-0.018528</td>\n",
       "      <td>-0.093937</td>\n",
       "      <td>1.593670</td>\n",
       "      <td>0.802364</td>\n",
       "      <td>0.317575</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3943210</th>\n",
       "      <td>0.214571</td>\n",
       "      <td>0.619006</td>\n",
       "      <td>0.007326</td>\n",
       "      <td>0.021136</td>\n",
       "      <td>0.044861</td>\n",
       "      <td>-87.933333</td>\n",
       "      <td>-0.036058</td>\n",
       "      <td>-0.168047</td>\n",
       "      <td>2.259385</td>\n",
       "      <td>0.783188</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004225</td>\n",
       "      <td>0.019472</td>\n",
       "      <td>0.129808</td>\n",
       "      <td>-206.076923</td>\n",
       "      <td>-0.130099</td>\n",
       "      <td>-0.296809</td>\n",
       "      <td>2.579902</td>\n",
       "      <td>0.559780</td>\n",
       "      <td>0.144231</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3955053</th>\n",
       "      <td>0.136049</td>\n",
       "      <td>0.323527</td>\n",
       "      <td>0.002728</td>\n",
       "      <td>0.006488</td>\n",
       "      <td>0.027045</td>\n",
       "      <td>-55.739130</td>\n",
       "      <td>-0.012144</td>\n",
       "      <td>-0.089263</td>\n",
       "      <td>2.039129</td>\n",
       "      <td>0.857491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000923</td>\n",
       "      <td>0.018928</td>\n",
       "      <td>0.033029</td>\n",
       "      <td>-109.736842</td>\n",
       "      <td>-0.032622</td>\n",
       "      <td>-0.133543</td>\n",
       "      <td>15.290985</td>\n",
       "      <td>0.745721</td>\n",
       "      <td>0.007854</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2119</th>\n",
       "      <td>0.021189</td>\n",
       "      <td>0.027153</td>\n",
       "      <td>0.010535</td>\n",
       "      <td>0.013501</td>\n",
       "      <td>0.026938</td>\n",
       "      <td>-202.714286</td>\n",
       "      <td>-0.056033</td>\n",
       "      <td>-2.644428</td>\n",
       "      <td>1.243611</td>\n",
       "      <td>0.970447</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027409</td>\n",
       "      <td>0.033392</td>\n",
       "      <td>0.020415</td>\n",
       "      <td>-54.027027</td>\n",
       "      <td>-0.013871</td>\n",
       "      <td>-0.190635</td>\n",
       "      <td>1.089482</td>\n",
       "      <td>0.894284</td>\n",
       "      <td>0.099652</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5287</th>\n",
       "      <td>0.011273</td>\n",
       "      <td>0.014781</td>\n",
       "      <td>0.049585</td>\n",
       "      <td>0.065016</td>\n",
       "      <td>0.025759</td>\n",
       "      <td>-146.089474</td>\n",
       "      <td>-0.036974</td>\n",
       "      <td>-3.279806</td>\n",
       "      <td>1.161031</td>\n",
       "      <td>0.885481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019518</td>\n",
       "      <td>0.026576</td>\n",
       "      <td>0.019127</td>\n",
       "      <td>-117.474074</td>\n",
       "      <td>-0.016851</td>\n",
       "      <td>-0.315633</td>\n",
       "      <td>1.137071</td>\n",
       "      <td>0.835123</td>\n",
       "      <td>0.171923</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14580</th>\n",
       "      <td>0.013777</td>\n",
       "      <td>0.021933</td>\n",
       "      <td>0.019251</td>\n",
       "      <td>0.030648</td>\n",
       "      <td>0.024712</td>\n",
       "      <td>-167.985294</td>\n",
       "      <td>-0.034895</td>\n",
       "      <td>-2.532816</td>\n",
       "      <td>1.428853</td>\n",
       "      <td>0.897531</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027041</td>\n",
       "      <td>0.043537</td>\n",
       "      <td>0.015867</td>\n",
       "      <td>-112.367347</td>\n",
       "      <td>-0.018190</td>\n",
       "      <td>-0.373981</td>\n",
       "      <td>1.392212</td>\n",
       "      <td>0.864703</td>\n",
       "      <td>0.134242</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16089</th>\n",
       "      <td>0.026086</td>\n",
       "      <td>0.033180</td>\n",
       "      <td>0.016793</td>\n",
       "      <td>0.021360</td>\n",
       "      <td>0.035915</td>\n",
       "      <td>-47.268293</td>\n",
       "      <td>-0.013510</td>\n",
       "      <td>-0.517905</td>\n",
       "      <td>1.201232</td>\n",
       "      <td>0.944399</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009702</td>\n",
       "      <td>0.013113</td>\n",
       "      <td>0.031403</td>\n",
       "      <td>-33.591837</td>\n",
       "      <td>-0.009242</td>\n",
       "      <td>-0.214546</td>\n",
       "      <td>1.257200</td>\n",
       "      <td>0.930169</td>\n",
       "      <td>0.109836</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20340</th>\n",
       "      <td>-0.002889</td>\n",
       "      <td>-0.004323</td>\n",
       "      <td>0.033421</td>\n",
       "      <td>0.050004</td>\n",
       "      <td>0.038156</td>\n",
       "      <td>-85.720000</td>\n",
       "      <td>-0.038219</td>\n",
       "      <td>13.228395</td>\n",
       "      <td>1.496825</td>\n",
       "      <td>1.000437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030728</td>\n",
       "      <td>0.041033</td>\n",
       "      <td>0.031948</td>\n",
       "      <td>-78.610169</td>\n",
       "      <td>-0.039566</td>\n",
       "      <td>-0.690281</td>\n",
       "      <td>1.253933</td>\n",
       "      <td>0.939014</td>\n",
       "      <td>0.055842</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21777</th>\n",
       "      <td>0.031178</td>\n",
       "      <td>0.042182</td>\n",
       "      <td>0.049781</td>\n",
       "      <td>0.067349</td>\n",
       "      <td>0.035927</td>\n",
       "      <td>-124.488372</td>\n",
       "      <td>-0.039927</td>\n",
       "      <td>-1.280622</td>\n",
       "      <td>1.235268</td>\n",
       "      <td>0.913037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024123</td>\n",
       "      <td>0.032881</td>\n",
       "      <td>0.024530</td>\n",
       "      <td>-82.464286</td>\n",
       "      <td>-0.024324</td>\n",
       "      <td>-0.354043</td>\n",
       "      <td>1.169397</td>\n",
       "      <td>0.857931</td>\n",
       "      <td>0.162695</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22173</th>\n",
       "      <td>0.002392</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.021713</td>\n",
       "      <td>0.033587</td>\n",
       "      <td>0.020029</td>\n",
       "      <td>-380.664835</td>\n",
       "      <td>-0.043749</td>\n",
       "      <td>-18.289599</td>\n",
       "      <td>1.454247</td>\n",
       "      <td>0.940120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015630</td>\n",
       "      <td>0.021525</td>\n",
       "      <td>0.015538</td>\n",
       "      <td>-227.235294</td>\n",
       "      <td>-0.022479</td>\n",
       "      <td>-0.370564</td>\n",
       "      <td>1.214269</td>\n",
       "      <td>0.881722</td>\n",
       "      <td>0.107992</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23306</th>\n",
       "      <td>0.084038</td>\n",
       "      <td>0.160622</td>\n",
       "      <td>0.024074</td>\n",
       "      <td>0.046013</td>\n",
       "      <td>0.069245</td>\n",
       "      <td>-143.000000</td>\n",
       "      <td>-0.058887</td>\n",
       "      <td>-0.700716</td>\n",
       "      <td>1.746322</td>\n",
       "      <td>0.913681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024534</td>\n",
       "      <td>0.048756</td>\n",
       "      <td>0.065922</td>\n",
       "      <td>-283.785714</td>\n",
       "      <td>-0.094178</td>\n",
       "      <td>-0.786110</td>\n",
       "      <td>1.745101</td>\n",
       "      <td>0.878135</td>\n",
       "      <td>0.119661</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27573</th>\n",
       "      <td>-0.017627</td>\n",
       "      <td>-0.023267</td>\n",
       "      <td>0.029558</td>\n",
       "      <td>0.039017</td>\n",
       "      <td>0.037323</td>\n",
       "      <td>-279.000000</td>\n",
       "      <td>-0.083033</td>\n",
       "      <td>4.710668</td>\n",
       "      <td>1.289227</td>\n",
       "      <td>0.976678</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011730</td>\n",
       "      <td>0.015720</td>\n",
       "      <td>0.032926</td>\n",
       "      <td>-44.434783</td>\n",
       "      <td>-0.011236</td>\n",
       "      <td>-0.127638</td>\n",
       "      <td>1.179074</td>\n",
       "      <td>0.879850</td>\n",
       "      <td>0.062170</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31263</th>\n",
       "      <td>0.012524</td>\n",
       "      <td>0.015753</td>\n",
       "      <td>0.027481</td>\n",
       "      <td>0.034567</td>\n",
       "      <td>0.028800</td>\n",
       "      <td>-144.646552</td>\n",
       "      <td>-0.031173</td>\n",
       "      <td>-2.489097</td>\n",
       "      <td>1.168560</td>\n",
       "      <td>0.929027</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027735</td>\n",
       "      <td>0.035221</td>\n",
       "      <td>0.021994</td>\n",
       "      <td>-173.753623</td>\n",
       "      <td>-0.036389</td>\n",
       "      <td>-1.095837</td>\n",
       "      <td>1.109918</td>\n",
       "      <td>0.874031</td>\n",
       "      <td>0.095989</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32251</th>\n",
       "      <td>0.004988</td>\n",
       "      <td>0.005586</td>\n",
       "      <td>0.018772</td>\n",
       "      <td>0.021022</td>\n",
       "      <td>0.034549</td>\n",
       "      <td>-180.941176</td>\n",
       "      <td>-0.032439</td>\n",
       "      <td>-6.503171</td>\n",
       "      <td>1.025828</td>\n",
       "      <td>0.916033</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017868</td>\n",
       "      <td>0.020642</td>\n",
       "      <td>0.022500</td>\n",
       "      <td>-57.520000</td>\n",
       "      <td>-0.011425</td>\n",
       "      <td>-0.138776</td>\n",
       "      <td>0.987380</td>\n",
       "      <td>0.854701</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33904</th>\n",
       "      <td>0.010595</td>\n",
       "      <td>0.020667</td>\n",
       "      <td>0.022352</td>\n",
       "      <td>0.043600</td>\n",
       "      <td>0.037493</td>\n",
       "      <td>-138.166667</td>\n",
       "      <td>-0.056666</td>\n",
       "      <td>-5.348387</td>\n",
       "      <td>1.791133</td>\n",
       "      <td>0.918247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038712</td>\n",
       "      <td>0.069400</td>\n",
       "      <td>0.037358</td>\n",
       "      <td>-36.750000</td>\n",
       "      <td>-0.012982</td>\n",
       "      <td>-0.162252</td>\n",
       "      <td>1.537418</td>\n",
       "      <td>0.857576</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34016</th>\n",
       "      <td>0.010713</td>\n",
       "      <td>0.014981</td>\n",
       "      <td>0.058804</td>\n",
       "      <td>0.082233</td>\n",
       "      <td>0.023762</td>\n",
       "      <td>-223.226667</td>\n",
       "      <td>-0.033843</td>\n",
       "      <td>-3.159166</td>\n",
       "      <td>1.228782</td>\n",
       "      <td>0.878697</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035173</td>\n",
       "      <td>0.045391</td>\n",
       "      <td>0.021468</td>\n",
       "      <td>-216.239496</td>\n",
       "      <td>-0.037346</td>\n",
       "      <td>-0.715517</td>\n",
       "      <td>1.064531</td>\n",
       "      <td>0.824894</td>\n",
       "      <td>0.107676</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34411</th>\n",
       "      <td>0.020499</td>\n",
       "      <td>0.026094</td>\n",
       "      <td>0.038796</td>\n",
       "      <td>0.049384</td>\n",
       "      <td>0.030165</td>\n",
       "      <td>-284.827586</td>\n",
       "      <td>-0.037362</td>\n",
       "      <td>-1.822595</td>\n",
       "      <td>1.113962</td>\n",
       "      <td>0.875119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031226</td>\n",
       "      <td>0.037144</td>\n",
       "      <td>0.065445</td>\n",
       "      <td>-272.043478</td>\n",
       "      <td>-0.048386</td>\n",
       "      <td>-0.757690</td>\n",
       "      <td>1.085387</td>\n",
       "      <td>0.912454</td>\n",
       "      <td>0.039934</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34578</th>\n",
       "      <td>0.008692</td>\n",
       "      <td>0.011787</td>\n",
       "      <td>0.013336</td>\n",
       "      <td>0.018086</td>\n",
       "      <td>0.029659</td>\n",
       "      <td>-188.203390</td>\n",
       "      <td>-0.045438</td>\n",
       "      <td>-5.227872</td>\n",
       "      <td>1.334539</td>\n",
       "      <td>0.984041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031267</td>\n",
       "      <td>0.044317</td>\n",
       "      <td>0.020444</td>\n",
       "      <td>-69.140351</td>\n",
       "      <td>-0.013545</td>\n",
       "      <td>-0.246945</td>\n",
       "      <td>1.308790</td>\n",
       "      <td>0.923375</td>\n",
       "      <td>0.054917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34673</th>\n",
       "      <td>0.010172</td>\n",
       "      <td>0.011030</td>\n",
       "      <td>0.034185</td>\n",
       "      <td>0.037065</td>\n",
       "      <td>0.033900</td>\n",
       "      <td>-283.527778</td>\n",
       "      <td>-0.040385</td>\n",
       "      <td>-3.970051</td>\n",
       "      <td>0.916123</td>\n",
       "      <td>0.844926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022535</td>\n",
       "      <td>0.025917</td>\n",
       "      <td>0.025562</td>\n",
       "      <td>-82.969697</td>\n",
       "      <td>-0.019501</td>\n",
       "      <td>-0.317744</td>\n",
       "      <td>0.918418</td>\n",
       "      <td>0.798565</td>\n",
       "      <td>0.007126</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35065</th>\n",
       "      <td>-0.007564</td>\n",
       "      <td>-0.009748</td>\n",
       "      <td>0.060122</td>\n",
       "      <td>0.077481</td>\n",
       "      <td>0.024202</td>\n",
       "      <td>-730.363636</td>\n",
       "      <td>-0.066304</td>\n",
       "      <td>8.765957</td>\n",
       "      <td>1.030615</td>\n",
       "      <td>0.799723</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014575</td>\n",
       "      <td>0.017957</td>\n",
       "      <td>0.018993</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.001231</td>\n",
       "      <td>0.853377</td>\n",
       "      <td>0.692656</td>\n",
       "      <td>0.028485</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35078</th>\n",
       "      <td>0.013828</td>\n",
       "      <td>0.016966</td>\n",
       "      <td>0.012092</td>\n",
       "      <td>0.014836</td>\n",
       "      <td>0.043895</td>\n",
       "      <td>-166.678571</td>\n",
       "      <td>-0.043783</td>\n",
       "      <td>-3.166214</td>\n",
       "      <td>1.058861</td>\n",
       "      <td>0.863042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011931</td>\n",
       "      <td>0.014825</td>\n",
       "      <td>0.038933</td>\n",
       "      <td>-260.531250</td>\n",
       "      <td>-0.056322</td>\n",
       "      <td>-1.211597</td>\n",
       "      <td>1.071457</td>\n",
       "      <td>0.862251</td>\n",
       "      <td>0.090959</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35250</th>\n",
       "      <td>0.012164</td>\n",
       "      <td>0.016146</td>\n",
       "      <td>0.044848</td>\n",
       "      <td>0.059531</td>\n",
       "      <td>0.043117</td>\n",
       "      <td>-136.866667</td>\n",
       "      <td>-0.044160</td>\n",
       "      <td>-3.630416</td>\n",
       "      <td>1.294027</td>\n",
       "      <td>0.974876</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042801</td>\n",
       "      <td>0.054961</td>\n",
       "      <td>0.031930</td>\n",
       "      <td>-209.064516</td>\n",
       "      <td>-0.050870</td>\n",
       "      <td>-0.754394</td>\n",
       "      <td>1.144725</td>\n",
       "      <td>0.891456</td>\n",
       "      <td>0.078279</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35463</th>\n",
       "      <td>-0.011542</td>\n",
       "      <td>-0.015655</td>\n",
       "      <td>0.043127</td>\n",
       "      <td>0.058498</td>\n",
       "      <td>0.032448</td>\n",
       "      <td>-371.479167</td>\n",
       "      <td>-0.087426</td>\n",
       "      <td>7.574766</td>\n",
       "      <td>1.264819</td>\n",
       "      <td>0.932470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025544</td>\n",
       "      <td>0.032467</td>\n",
       "      <td>0.023007</td>\n",
       "      <td>-108.312500</td>\n",
       "      <td>-0.021004</td>\n",
       "      <td>-0.314824</td>\n",
       "      <td>1.068904</td>\n",
       "      <td>0.840984</td>\n",
       "      <td>0.082483</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35561</th>\n",
       "      <td>0.020170</td>\n",
       "      <td>0.029097</td>\n",
       "      <td>0.019904</td>\n",
       "      <td>0.028713</td>\n",
       "      <td>0.031462</td>\n",
       "      <td>-45.466667</td>\n",
       "      <td>-0.012109</td>\n",
       "      <td>-0.600352</td>\n",
       "      <td>1.338384</td>\n",
       "      <td>0.927754</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018294</td>\n",
       "      <td>0.025201</td>\n",
       "      <td>0.037145</td>\n",
       "      <td>-80.461538</td>\n",
       "      <td>-0.025312</td>\n",
       "      <td>-0.504826</td>\n",
       "      <td>1.188953</td>\n",
       "      <td>0.863106</td>\n",
       "      <td>0.083011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57831</th>\n",
       "      <td>0.012231</td>\n",
       "      <td>0.017436</td>\n",
       "      <td>0.051597</td>\n",
       "      <td>0.073555</td>\n",
       "      <td>0.019168</td>\n",
       "      <td>-649.176471</td>\n",
       "      <td>-0.076783</td>\n",
       "      <td>-6.277588</td>\n",
       "      <td>1.404174</td>\n",
       "      <td>0.985000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028071</td>\n",
       "      <td>0.035598</td>\n",
       "      <td>0.012416</td>\n",
       "      <td>-79.000000</td>\n",
       "      <td>-0.007375</td>\n",
       "      <td>-0.089023</td>\n",
       "      <td>1.059093</td>\n",
       "      <td>0.835158</td>\n",
       "      <td>0.038038</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57885</th>\n",
       "      <td>0.012729</td>\n",
       "      <td>0.016995</td>\n",
       "      <td>0.012958</td>\n",
       "      <td>0.017301</td>\n",
       "      <td>0.053146</td>\n",
       "      <td>-130.133333</td>\n",
       "      <td>-0.040667</td>\n",
       "      <td>-3.194763</td>\n",
       "      <td>1.307669</td>\n",
       "      <td>0.979417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022320</td>\n",
       "      <td>0.030845</td>\n",
       "      <td>0.042891</td>\n",
       "      <td>-129.058824</td>\n",
       "      <td>-0.033657</td>\n",
       "      <td>-0.702530</td>\n",
       "      <td>1.305039</td>\n",
       "      <td>0.944346</td>\n",
       "      <td>0.075336</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58052</th>\n",
       "      <td>0.100384</td>\n",
       "      <td>0.154226</td>\n",
       "      <td>0.008260</td>\n",
       "      <td>0.012691</td>\n",
       "      <td>0.017871</td>\n",
       "      <td>14.166667</td>\n",
       "      <td>0.002660</td>\n",
       "      <td>0.026494</td>\n",
       "      <td>1.248251</td>\n",
       "      <td>0.812473</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017433</td>\n",
       "      <td>0.022208</td>\n",
       "      <td>0.016488</td>\n",
       "      <td>4.555556</td>\n",
       "      <td>0.001028</td>\n",
       "      <td>0.009275</td>\n",
       "      <td>1.091887</td>\n",
       "      <td>0.857119</td>\n",
       "      <td>0.078200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58087</th>\n",
       "      <td>-0.035312</td>\n",
       "      <td>-0.042002</td>\n",
       "      <td>0.039661</td>\n",
       "      <td>0.047176</td>\n",
       "      <td>0.050428</td>\n",
       "      <td>-749.352941</td>\n",
       "      <td>-0.129153</td>\n",
       "      <td>3.657479</td>\n",
       "      <td>1.219514</td>\n",
       "      <td>1.025265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013404</td>\n",
       "      <td>0.015617</td>\n",
       "      <td>0.026164</td>\n",
       "      <td>-26.263158</td>\n",
       "      <td>-0.004170</td>\n",
       "      <td>-0.047120</td>\n",
       "      <td>1.033687</td>\n",
       "      <td>0.887212</td>\n",
       "      <td>0.071206</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58205</th>\n",
       "      <td>0.000285</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>0.036055</td>\n",
       "      <td>0.047747</td>\n",
       "      <td>0.035919</td>\n",
       "      <td>-345.900000</td>\n",
       "      <td>-0.039404</td>\n",
       "      <td>-138.360000</td>\n",
       "      <td>1.057990</td>\n",
       "      <td>0.798922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024235</td>\n",
       "      <td>0.029895</td>\n",
       "      <td>0.033766</td>\n",
       "      <td>-217.058824</td>\n",
       "      <td>-0.033182</td>\n",
       "      <td>-0.813134</td>\n",
       "      <td>0.975352</td>\n",
       "      <td>0.790666</td>\n",
       "      <td>0.099546</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6898 rows  56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             EQTA      EQTL     LLRTA     LLRGL     OEXTA      INCEMP  \\\n",
       "37       0.212297  0.390905  0.010553  0.019431  0.021300   22.347826   \n",
       "242      0.138115  0.208180  0.005476  0.008254  0.020049   32.500000   \n",
       "279      0.148749  0.309703  0.003029  0.006306  0.020605   17.475000   \n",
       "354      0.107925  0.244104  0.022419  0.050708  0.025443    2.750000   \n",
       "457      0.083266  0.105280  0.010631  0.013441  0.017548   44.000000   \n",
       "505      0.077013  0.122921  0.011596  0.018508  0.020537   18.592593   \n",
       "1155     0.098782  0.133240  0.010796  0.014562  0.021385   31.821429   \n",
       "1351     0.137449  0.282032  0.009761  0.020028  0.012637   53.724138   \n",
       "1454     0.106132  0.239352  0.006746  0.015214  0.023092   45.738255   \n",
       "1557     0.096508  0.170844  0.006890  0.012196  0.014719   36.750000   \n",
       "1669     0.182143  0.539039  0.008249  0.024414  0.014856   47.122807   \n",
       "1829     0.101380  0.175248  0.009586  0.016571  0.019664   27.076087   \n",
       "1856     0.121966  0.695801  0.001157  0.006600  0.008081   34.125000   \n",
       "2040     0.097353  0.131587  0.016861  0.022790  0.019106   19.347826   \n",
       "2161     0.111464  0.231983  0.004719  0.009820  0.021137   55.000000   \n",
       "2376     0.163295  0.261252  0.011117  0.017786  0.014525   38.883978   \n",
       "2554     0.111775  0.199361  0.008261  0.014735  0.019110   23.000000   \n",
       "2732     0.139267  0.183945  0.008706  0.011498  0.017158   22.790000   \n",
       "2750     0.097927  0.143254  0.010779  0.015768  0.017180   35.909091   \n",
       "3252     0.120849  0.256903  0.008299  0.017642  0.014164   76.764706   \n",
       "3458     0.101578  0.221555  0.009057  0.019754  0.016418   12.636364   \n",
       "3720     0.143787  0.241168  0.007816  0.013109  0.023006   30.637931   \n",
       "3953     0.069926  0.074322  0.022649  0.024073  0.029820  -27.894737   \n",
       "4138     0.090290  0.132076  0.016210  0.023712  0.032817  -11.929825   \n",
       "4156     0.102335  0.136832  0.011378  0.015214  0.024893   22.983051   \n",
       "4231     0.115423  0.175452  0.005928  0.009011  0.018150    8.212121   \n",
       "4437     0.098129  0.160124  0.012109  0.019759  0.020315   15.661538   \n",
       "4839     0.100318  0.130596  0.013187  0.017167  0.026015   25.915663   \n",
       "5005     0.065712  0.093764  0.006650  0.009489  0.031140  -35.040000   \n",
       "5069     0.225603  0.263607  0.060829  0.071075  0.007864  584.551724   \n",
       "...           ...       ...       ...       ...       ...         ...   \n",
       "3897434  0.169637  0.312125  0.007470  0.013745  0.028984  -62.222222   \n",
       "3900950  0.137348  0.215121  0.008342  0.013066  0.023643   -9.612903   \n",
       "3943210  0.214571  0.619006  0.007326  0.021136  0.044861  -87.933333   \n",
       "3955053  0.136049  0.323527  0.002728  0.006488  0.027045  -55.739130   \n",
       "2119     0.021189  0.027153  0.010535  0.013501  0.026938 -202.714286   \n",
       "5287     0.011273  0.014781  0.049585  0.065016  0.025759 -146.089474   \n",
       "14580    0.013777  0.021933  0.019251  0.030648  0.024712 -167.985294   \n",
       "16089    0.026086  0.033180  0.016793  0.021360  0.035915  -47.268293   \n",
       "20340   -0.002889 -0.004323  0.033421  0.050004  0.038156  -85.720000   \n",
       "21777    0.031178  0.042182  0.049781  0.067349  0.035927 -124.488372   \n",
       "22173    0.002392  0.003700  0.021713  0.033587  0.020029 -380.664835   \n",
       "23306    0.084038  0.160622  0.024074  0.046013  0.069245 -143.000000   \n",
       "27573   -0.017627 -0.023267  0.029558  0.039017  0.037323 -279.000000   \n",
       "31263    0.012524  0.015753  0.027481  0.034567  0.028800 -144.646552   \n",
       "32251    0.004988  0.005586  0.018772  0.021022  0.034549 -180.941176   \n",
       "33904    0.010595  0.020667  0.022352  0.043600  0.037493 -138.166667   \n",
       "34016    0.010713  0.014981  0.058804  0.082233  0.023762 -223.226667   \n",
       "34411    0.020499  0.026094  0.038796  0.049384  0.030165 -284.827586   \n",
       "34578    0.008692  0.011787  0.013336  0.018086  0.029659 -188.203390   \n",
       "34673    0.010172  0.011030  0.034185  0.037065  0.033900 -283.527778   \n",
       "35065   -0.007564 -0.009748  0.060122  0.077481  0.024202 -730.363636   \n",
       "35078    0.013828  0.016966  0.012092  0.014836  0.043895 -166.678571   \n",
       "35250    0.012164  0.016146  0.044848  0.059531  0.043117 -136.866667   \n",
       "35463   -0.011542 -0.015655  0.043127  0.058498  0.032448 -371.479167   \n",
       "35561    0.020170  0.029097  0.019904  0.028713  0.031462  -45.466667   \n",
       "57831    0.012231  0.017436  0.051597  0.073555  0.019168 -649.176471   \n",
       "57885    0.012729  0.016995  0.012958  0.017301  0.053146 -130.133333   \n",
       "58052    0.100384  0.154226  0.008260  0.012691  0.017871   14.166667   \n",
       "58087   -0.035312 -0.042002  0.039661  0.047176  0.050428 -749.352941   \n",
       "58205    0.000285  0.000377  0.036055  0.047747  0.035919 -345.900000   \n",
       "\n",
       "              ROA         ROE      TDTL      TDTA  ...  LLRTA-4Q  LLRGL-4Q  \\\n",
       "37       0.006235    0.029368  1.438278  0.781116  ...  0.011724  0.021130   \n",
       "242      0.014078    0.101927  1.082964  0.718480  ...  0.005004  0.007882   \n",
       "279      0.004466    0.030024  1.388137  0.666716  ...  0.003401  0.007432   \n",
       "354      0.001147    0.010628  2.014151  0.890511  ...  0.022978  0.044882   \n",
       "457      0.010071    0.120953  1.007846  0.797101  ...  0.012244  0.013760   \n",
       "505      0.005170    0.067128  1.272360  0.797165  ...  0.011893  0.017178   \n",
       "1155     0.009028    0.091394  1.130753  0.838320  ...  0.009800  0.014763   \n",
       "1351     0.010620    0.077263  1.760402  0.857936  ...  0.008064  0.015834   \n",
       "1454     0.013856    0.130553  2.010991  0.891697  ...  0.006391  0.014072   \n",
       "1557     0.007975    0.082631  1.518262  0.857652  ...  0.008291  0.013245   \n",
       "1669     0.010788    0.059227  2.410124  0.814387  ...  0.007971  0.024153   \n",
       "1829     0.006001    0.059195  1.380148  0.798408  ...  0.010035  0.017037   \n",
       "1856     0.001564    0.012820  3.238196  0.567618  ...  0.001180  0.018165   \n",
       "2040     0.004296    0.044129  1.058551  0.783156  ...  0.013091  0.018169   \n",
       "2161     0.014565    0.130670  1.816885  0.872984  ...  0.004525  0.009406   \n",
       "2376     0.002897    0.017741  0.850152  0.531386  ...  0.011218  0.016716   \n",
       "2554     0.009157    0.081923  1.512871  0.848213  ...  0.006750  0.012025   \n",
       "2732     0.004304    0.030902  1.129128  0.854877  ...  0.008571  0.010788   \n",
       "2750     0.006946    0.070928  1.137723  0.777735  ...  0.009461  0.012816   \n",
       "3252     0.016585    0.137238  1.816704  0.854591  ...  0.007178  0.015256   \n",
       "3458     0.004448    0.043793  1.746056  0.800525  ...  0.009207  0.020592   \n",
       "3720     0.009229    0.064182  1.344805  0.801792  ...  0.008663  0.015367   \n",
       "3953    -0.008778   -0.125533  0.910723  0.856845  ...  0.015320  0.016101   \n",
       "4138    -0.003798   -0.042069  1.302556  0.890455  ...  0.014759  0.021005   \n",
       "4156     0.007244    0.070784  0.980858  0.733576  ...  0.012397  0.017842   \n",
       "4231     0.002114    0.018313  1.332100  0.876333  ...  0.008918  0.013762   \n",
       "4437     0.003857    0.039305  1.414022  0.866563  ...  0.012017  0.017486   \n",
       "4839     0.006959    0.069371  1.055053  0.810445  ...  0.011306  0.014848   \n",
       "5005    -0.009028   -0.137390  1.109632  0.777649  ...  0.020428  0.025559   \n",
       "5069     0.034226    0.151709  0.888147  0.760104  ...  0.039154  0.043390   \n",
       "...           ...         ...       ...       ...  ...       ...       ...   \n",
       "3897434 -0.015212   -0.089672  1.489954  0.809773  ...  0.006125  0.014269   \n",
       "3900950 -0.002625   -0.019112  1.349696  0.861736  ...  0.006748  0.013403   \n",
       "3943210 -0.036058   -0.168047  2.259385  0.783188  ...  0.004225  0.019472   \n",
       "3955053 -0.012144   -0.089263  2.039129  0.857491  ...  0.000923  0.018928   \n",
       "2119    -0.056033   -2.644428  1.243611  0.970447  ...  0.027409  0.033392   \n",
       "5287    -0.036974   -3.279806  1.161031  0.885481  ...  0.019518  0.026576   \n",
       "14580   -0.034895   -2.532816  1.428853  0.897531  ...  0.027041  0.043537   \n",
       "16089   -0.013510   -0.517905  1.201232  0.944399  ...  0.009702  0.013113   \n",
       "20340   -0.038219   13.228395  1.496825  1.000437  ...  0.030728  0.041033   \n",
       "21777   -0.039927   -1.280622  1.235268  0.913037  ...  0.024123  0.032881   \n",
       "22173   -0.043749  -18.289599  1.454247  0.940120  ...  0.015630  0.021525   \n",
       "23306   -0.058887   -0.700716  1.746322  0.913681  ...  0.024534  0.048756   \n",
       "27573   -0.083033    4.710668  1.289227  0.976678  ...  0.011730  0.015720   \n",
       "31263   -0.031173   -2.489097  1.168560  0.929027  ...  0.027735  0.035221   \n",
       "32251   -0.032439   -6.503171  1.025828  0.916033  ...  0.017868  0.020642   \n",
       "33904   -0.056666   -5.348387  1.791133  0.918247  ...  0.038712  0.069400   \n",
       "34016   -0.033843   -3.159166  1.228782  0.878697  ...  0.035173  0.045391   \n",
       "34411   -0.037362   -1.822595  1.113962  0.875119  ...  0.031226  0.037144   \n",
       "34578   -0.045438   -5.227872  1.334539  0.984041  ...  0.031267  0.044317   \n",
       "34673   -0.040385   -3.970051  0.916123  0.844926  ...  0.022535  0.025917   \n",
       "35065   -0.066304    8.765957  1.030615  0.799723  ...  0.014575  0.017957   \n",
       "35078   -0.043783   -3.166214  1.058861  0.863042  ...  0.011931  0.014825   \n",
       "35250   -0.044160   -3.630416  1.294027  0.974876  ...  0.042801  0.054961   \n",
       "35463   -0.087426    7.574766  1.264819  0.932470  ...  0.025544  0.032467   \n",
       "35561   -0.012109   -0.600352  1.338384  0.927754  ...  0.018294  0.025201   \n",
       "57831   -0.076783   -6.277588  1.404174  0.985000  ...  0.028071  0.035598   \n",
       "57885   -0.040667   -3.194763  1.307669  0.979417  ...  0.022320  0.030845   \n",
       "58052    0.002660    0.026494  1.248251  0.812473  ...  0.017433  0.022208   \n",
       "58087   -0.129153    3.657479  1.219514  1.025265  ...  0.013404  0.015617   \n",
       "58205   -0.039404 -138.360000  1.057990  0.798922  ...  0.024235  0.029895   \n",
       "\n",
       "         OEXTA-4Q   INCEMP-4Q    ROA-4Q    ROE-4Q    TDTL-4Q   TDTA-4Q  \\\n",
       "37       0.028695   24.120000  0.007341  0.036028   1.428885  0.792783   \n",
       "242      0.027000   39.538462  0.015403  0.120178   1.196574  0.759754   \n",
       "279      0.026377    9.475000  0.002446  0.016889   1.389068  0.635692   \n",
       "354      0.041032    6.500000  0.003048  0.025794   1.658118  0.848886   \n",
       "457      0.025836   35.333333  0.008930  0.097997   0.906047  0.806229   \n",
       "505      0.031016   22.845455  0.006874  0.089798   1.142031  0.790691   \n",
       "1155     0.024293   50.980769  0.011771  0.155548   1.305846  0.866845   \n",
       "1351     0.017072   94.678571  0.019088  0.137052   1.682010  0.856658   \n",
       "1454     0.034547   48.530201  0.015703  0.159154   1.978913  0.898765   \n",
       "1557     0.022451   47.727273  0.011454  0.103693   1.332381  0.834010   \n",
       "1669     0.020969   52.152542  0.012546  0.073255   2.496510  0.823894   \n",
       "1829     0.027167   29.031915  0.006645  0.067266   1.360503  0.801319   \n",
       "1856     0.009791  371.000000  0.017125  0.221993   9.922287  0.644366   \n",
       "2040     0.022769   37.521739  0.007802  0.092448   1.090574  0.785773   \n",
       "2161     0.028190   63.437500  0.016346  0.160284   1.839523  0.884976   \n",
       "2376     0.014932   54.598870  0.004891  0.049744   0.923529  0.619765   \n",
       "2554     0.025362   31.750000  0.012247  0.112489   1.582374  0.888235   \n",
       "2732     0.022737   24.250000  0.004614  0.033576   1.078822  0.857105   \n",
       "2750     0.025072   35.909091  0.007187  0.075874   1.088211  0.803319   \n",
       "3252     0.022715   88.558824  0.019847  0.172709   1.826539  0.859422   \n",
       "3458     0.029546  -62.090909 -0.023910 -0.228887   1.809270  0.808934   \n",
       "3720     0.031594   31.842105  0.009581  0.069969   1.446861  0.815599   \n",
       "3953     0.036605   29.368421  0.008854  0.113024   0.867616  0.825517   \n",
       "4138     0.038339   -2.283582 -0.000816 -0.009446   1.275345  0.896120   \n",
       "4156     0.034520    5.176471  0.001719  0.019546   1.127239  0.783229   \n",
       "4231     0.023722    7.441176  0.001983  0.017752   1.361838  0.882495   \n",
       "4437     0.025459   17.126984  0.004191  0.044785   1.233140  0.847450   \n",
       "4839     0.035159   14.305882  0.003907  0.046640   1.055074  0.803433   \n",
       "5005     0.036077  -88.644231 -0.021812 -0.330217   0.961760  0.768697   \n",
       "5069     0.007395  791.464286  0.044872  0.216833   0.869779  0.784867   \n",
       "...           ...         ...       ...       ...        ...       ...   \n",
       "3897434  0.073571 -269.250000 -0.071320 -0.324691   1.807019  0.775710   \n",
       "3900950  0.036561  -47.032258 -0.018528 -0.093937   1.593670  0.802364   \n",
       "3943210  0.129808 -206.076923 -0.130099 -0.296809   2.579902  0.559780   \n",
       "3955053  0.033029 -109.736842 -0.032622 -0.133543  15.290985  0.745721   \n",
       "2119     0.020415  -54.027027 -0.013871 -0.190635   1.089482  0.894284   \n",
       "5287     0.019127 -117.474074 -0.016851 -0.315633   1.137071  0.835123   \n",
       "14580    0.015867 -112.367347 -0.018190 -0.373981   1.392212  0.864703   \n",
       "16089    0.031403  -33.591837 -0.009242 -0.214546   1.257200  0.930169   \n",
       "20340    0.031948  -78.610169 -0.039566 -0.690281   1.253933  0.939014   \n",
       "21777    0.024530  -82.464286 -0.024324 -0.354043   1.169397  0.857931   \n",
       "22173    0.015538 -227.235294 -0.022479 -0.370564   1.214269  0.881722   \n",
       "23306    0.065922 -283.785714 -0.094178 -0.786110   1.745101  0.878135   \n",
       "27573    0.032926  -44.434783 -0.011236 -0.127638   1.179074  0.879850   \n",
       "31263    0.021994 -173.753623 -0.036389 -1.095837   1.109918  0.874031   \n",
       "32251    0.022500  -57.520000 -0.011425 -0.138776   0.987380  0.854701   \n",
       "33904    0.037358  -36.750000 -0.012982 -0.162252   1.537418  0.857576   \n",
       "34016    0.021468 -216.239496 -0.037346 -0.715517   1.064531  0.824894   \n",
       "34411    0.065445 -272.043478 -0.048386 -0.757690   1.085387  0.912454   \n",
       "34578    0.020444  -69.140351 -0.013545 -0.246945   1.308790  0.923375   \n",
       "34673    0.025562  -82.969697 -0.019501 -0.317744   0.918418  0.798565   \n",
       "35065    0.018993    0.735294  0.000099  0.001231   0.853377  0.692656   \n",
       "35078    0.038933 -260.531250 -0.056322 -1.211597   1.071457  0.862251   \n",
       "35250    0.031930 -209.064516 -0.050870 -0.754394   1.144725  0.891456   \n",
       "35463    0.023007 -108.312500 -0.021004 -0.314824   1.068904  0.840984   \n",
       "35561    0.037145  -80.461538 -0.025312 -0.504826   1.188953  0.863106   \n",
       "57831    0.012416  -79.000000 -0.007375 -0.089023   1.059093  0.835158   \n",
       "57885    0.042891 -129.058824 -0.033657 -0.702530   1.305039  0.944346   \n",
       "58052    0.016488    4.555556  0.001028  0.009275   1.091887  0.857119   \n",
       "58087    0.026164  -26.263158 -0.004170 -0.047120   1.033687  0.887212   \n",
       "58205    0.033766 -217.058824 -0.033182 -0.813134   0.975352  0.790666   \n",
       "\n",
       "          TATA-4Q  Target  \n",
       "37       0.373285       0  \n",
       "242      0.257836       0  \n",
       "279      0.145053       0  \n",
       "354      0.447362       0  \n",
       "457      0.014350       0  \n",
       "505      0.199013       0  \n",
       "1155     0.133354       0  \n",
       "1351     0.026986       0  \n",
       "1454     0.430634       0  \n",
       "1557     0.110638       0  \n",
       "1669     0.147797       0  \n",
       "1829     0.191627       0  \n",
       "1856     0.449337       0  \n",
       "2040     0.207786       0  \n",
       "2161     0.344969       0  \n",
       "2376     0.211138       0  \n",
       "2554     0.001157       0  \n",
       "2732     0.112309       0  \n",
       "2750     0.214676       0  \n",
       "3252     0.433962       0  \n",
       "3458     0.262550       0  \n",
       "3720     0.206984       0  \n",
       "3953     0.000032       0  \n",
       "4138     0.171738       0  \n",
       "4156     0.176553       0  \n",
       "4231     0.225974       0  \n",
       "4437     0.219132       0  \n",
       "4839     0.179947       0  \n",
       "5005     0.136367       0  \n",
       "5069     0.038237       0  \n",
       "...           ...     ...  \n",
       "3897434  0.382889       0  \n",
       "3900950  0.317575       0  \n",
       "3943210  0.144231       0  \n",
       "3955053  0.007854       0  \n",
       "2119     0.099652       1  \n",
       "5287     0.171923       1  \n",
       "14580    0.134242       1  \n",
       "16089    0.109836       1  \n",
       "20340    0.055842       1  \n",
       "21777    0.162695       1  \n",
       "22173    0.107992       1  \n",
       "23306    0.119661       1  \n",
       "27573    0.062170       1  \n",
       "31263    0.095989       1  \n",
       "32251    0.000008       1  \n",
       "33904    0.000000       1  \n",
       "34016    0.107676       1  \n",
       "34411    0.039934       1  \n",
       "34578    0.054917       1  \n",
       "34673    0.007126       1  \n",
       "35065    0.028485       1  \n",
       "35078    0.090959       1  \n",
       "35250    0.078279       1  \n",
       "35463    0.082483       1  \n",
       "35561    0.083011       1  \n",
       "57831    0.038038       1  \n",
       "57885    0.075336       1  \n",
       "58052    0.078200       1  \n",
       "58087    0.071206       1  \n",
       "58205    0.099546       1  \n",
       "\n",
       "[6898 rows x 56 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "camel_data.dropna(inplace=True)\n",
    "camel_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6892, 56)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#camel_data.replace(np.inf, '', inplace=True)\n",
    "#df[~df.isin([np.nan, np.inf, -np.inf]).any(1)]\n",
    "camel_set = camel_data[~camel_data.isin([np.nan, 'NaN', np.inf, -np.inf]).any(1)]\n",
    "\n",
    "#camel_set = camel_data.dropna()\n",
    "camel_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#camel_set.columns\n",
    "len(camel_set.loc[camel_set['Target'] ==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = camel_set['Target']\n",
    "X = camel_set.drop(['Target'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_std = scaler.transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=1, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression(random_state=1)\n",
    "log_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5483,    9],\n",
       "       [  10,   11]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_y_train_pred = cross_val_predict(log_reg, X_train_std, y_train, cv=3)\n",
    "confusion_matrix(y_train, log_y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5365853658536585"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_train, log_y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0906 16:33:01.165156 4722406848 deprecation.py:506] From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Please provide as model inputs either a single array or a list of arrays. You passed: x=             EQTA      EQTL     LLRTA     LLRGL     OEXTA      INCEMP  \\\n487142   0.135469  0.219712  0.004861  0.007883  0.015192   35.090909   \n3593307  0.092253  0.104042  0.036328  0.040970  0.012562   25.666667   \n3134250  0.082356  0.100571  0.008513  0.010396  0.036723    4.153846   \n537355   0.087692  0.207520  0.005452  0.012901  0.024309   10.622222   \n307062   0.127852  0.186926  0.027541  0.040266  0.021548    8.466667   \n3482894  0.128233  0.174938  0.013176  0.017974  0.026977  -11.821429   \n2078290  0.134291  0.227563  0.014798  0.025075  0.025034   16.555455   \n518354   0.148720  0.205192  0.012503  0.017251  0.052498    7.347826   \n904667   0.076193  0.176231  0.004657  0.010771  0.027759   17.541667   \n613334   0.108285  0.182628  0.005635  0.009504  0.016728   26.818182   \n391418   0.179367  0.398005  0.013135  0.029146  0.029504    5.166667   \n349129   0.162108  0.356917  0.007100  0.015632  0.019909   25.704545   \n2140348  0.074561  0.098370  0.013868  0.018296  0.019760   10.393939   \n117458   0.115381  0.168465  0.011076  0.016171  0.016834   24.054054   \n834979   0.055454  0.066917  0.019895  0.024007  0.023497  -61.342105   \n340144   0.099588  0.134056  0.013343  0.017962  0.019614   31.480000   \n2068107  0.139172  0.213593  0.025532  0.039184  0.034852  -39.657895   \n158947   0.126356  0.189798  0.008001  0.012019  0.018810   36.885246   \n122153   0.128872  0.414666  0.006031  0.019407  0.024545    6.941176   \n750154   0.077829  0.108996  0.008580  0.012016  0.018551   43.883333   \n722227   0.043545  0.061762  0.020988  0.029768  0.042536   -9.666667   \n6141     0.090484  0.202586  0.006494  0.014540  0.016302   26.090909   \n444677   0.106678  0.139776  0.001241  0.001626  0.019108   22.333333   \n2936840  0.093773  0.138799  0.017552  0.025981  0.030092   -6.625000   \n937759   0.126390  0.217976  0.006359  0.010967  0.020328   36.515152   \n803658   0.154279  0.260325  0.008834  0.014907  0.018338   42.666667   \n200435   0.093891  0.128525  0.012523  0.017142  0.019415   44.386667   \n719030   0.108328  0.181117  0.005800  0.009698  0.018258   43.100000   \n3548763  0.139389  0.217168  0.009648  0.015032  0.023446   17.000000   \n3067929  0.111422  0.147760  0.049365  0.065465  0.021013  -79.921053   \n...           ...       ...       ...       ...       ...         ...   \n999935   0.108819  0.165464  0.019108  0.029055  0.026945    0.466019   \n412845   0.092181  0.178049  0.005764  0.011134  0.015931   28.635135   \n3623969  0.135794  0.244630  0.015847  0.028548  0.026008   34.629630   \n794345   0.146918  0.418587  0.005396  0.015374  0.008319   51.000000   \n895831   0.039422  0.051168  0.037432  0.048585  0.028732 -130.747253   \n173342   0.111518  0.290531  0.009037  0.023542  0.016247   60.312500   \n805876   0.132621  0.172537  0.005226  0.006799  0.021379   14.341463   \n1225798  0.151043  0.161415  0.016558  0.017695  0.018774   67.181818   \n477303   0.088201  0.106185  0.006826  0.008218  0.023050   13.271930   \n1669     0.182143  0.539039  0.008249  0.024414  0.014856   47.122807   \n3602889  0.103090  0.144379  0.011877  0.016633  0.015670   31.095238   \n429759   0.115882  0.152323  0.008917  0.011721  0.028019   25.063830   \n4156     0.102335  0.136832  0.011378  0.015214  0.024893   22.983051   \n384353   0.092425  0.140796  0.009963  0.015177  0.025054   21.250000   \n2948423  0.085382  0.160420  0.009637  0.018107  0.019580   32.076923   \n289739   0.094039  0.113379  0.007408  0.008932  0.023780   22.837209   \n3824542  0.178554  0.263851  0.008153  0.012047  0.022823  -29.400000   \n1189993  0.153063  0.232305  0.023306  0.035372  0.019617   35.135542   \n3217957  0.095562  0.126489  0.026261  0.034759  0.021369    9.106383   \n190451   0.103257  0.158285  0.006139  0.009411  0.020435   26.453333   \n1929247  0.089601  0.215439  0.006852  0.016476  0.034269   15.038356   \n899642   0.101737  0.161720  0.007851  0.012479  0.022150   31.322581   \n128258   0.092568  0.245541  0.004122  0.010934  0.033177    3.076923   \n255547   0.116696  0.169720  0.009417  0.013696  0.018711   41.866667   \n790703   0.093573  0.111329  0.008866  0.010548  0.021677   17.333333   \n702836   0.104390  0.164841  0.007787  0.012297  0.022364    8.645161   \n3351598  0.012729  0.016995  0.012958  0.017301  0.053146 -130.133333   \n954671   0.083234  0.105325  0.010639  0.013462  0.030926   10.825000   \n489155   0.080357  0.121918  0.003092  0.004691  0.021610   10.750000   \n183846   0.169514  0.279477  0.007186  0.011847  0.023957   20.589041   \n\n              ROA       ROE      TDTL      TDTA  ...   EQTL-4Q  LLRTA-4Q  \\\n487142   0.007850  0.057949  1.390573  0.857393  ...  0.219331  0.005631   \n3593307  0.003842  0.041644  0.980606  0.869490  ...  0.115903  0.025644   \n3134250  0.001654  0.020079  0.934364  0.765143  ...  0.092728  0.007699   \n537355   0.004365  0.049776  2.102950  0.888647  ...  0.193911  0.007593   \n307062   0.002068  0.016177  1.270097  0.868712  ...  0.162100  0.032975   \n3482894 -0.002327 -0.018148  1.078908  0.790864  ...  0.178732  0.014612   \n2078290  0.004292  0.031960  1.384858  0.817240  ...  0.230841  0.016710   \n518354   0.004119  0.027696  1.135113  0.822715  ...  0.208783  0.013134   \n904667   0.006657  0.087372  2.125357  0.918890  ...  0.177338  0.004462   \n613334   0.007488  0.069151  1.498138  0.888288  ...  0.190050  0.005469   \n391418   0.002075  0.011569  1.759689  0.793029  ...  0.379252  0.007919   \n349129   0.008588  0.052977  1.835794  0.833799  ...  0.334473  0.007731   \n2140348  0.002048  0.027462  1.043680  0.791079  ...  0.091393  0.016142   \n117458   0.006699  0.058058  1.177048  0.806153  ...  0.150928  0.007527   \n834979  -0.016508 -0.297695  0.929028  0.769886  ...  0.088498  0.019076   \n340144   0.006562  0.065896  1.017093  0.755581  ...  0.126852  0.012547   \n2068107 -0.013771 -0.098949  1.307066  0.851654  ...  0.190256  0.023585   \n158947   0.006771  0.053584  1.228648  0.817956  ...  0.182142  0.008376   \n122153   0.002252  0.017476  2.777437  0.863188  ...  0.383238  0.004826   \n750154   0.012172  0.156391  1.286908  0.918917  ...  0.107165  0.007292   \n722227  -0.004876 -0.111969  1.352172  0.953344  ...  0.090439  0.028958   \n6141     0.005434  0.060054  2.029462  0.906449  ...  0.211396  0.008531   \n444677   0.003695  0.034634  1.165282  0.889351  ...  0.134106  0.000636   \n2936840 -0.002172 -0.023161  1.337444  0.903577  ...  0.126431  0.010341   \n937759   0.010468  0.082824  1.492913  0.865644  ...  0.224580  0.005402   \n803658   0.010374  0.067245  1.407891  0.834373  ...  0.276373  0.007850   \n200435   0.011942  0.127185  1.202771  0.878662  ...  0.103804  0.014219   \n719030   0.007862  0.072571  1.476289  0.882989  ...  0.168435  0.005419   \n3548763  0.004286  0.030748  1.306679  0.838687  ...  0.199519  0.008692   \n3067929 -0.014474 -0.129903  0.951739  0.717682  ...  0.188183  0.041104   \n...           ...       ...       ...       ...  ...       ...       ...   \n999935   0.000179  0.001648  1.319114  0.867532  ...  0.157289  0.018666   \n412845   0.007271  0.078873  1.702123  0.881238  ...  0.172329  0.005626   \n3623969  0.010698  0.078783  1.525457  0.846780  ...  0.255154  0.016017   \n794345   0.004215  0.028692  2.310042  0.810792  ...  0.360378  0.010324   \n895831  -0.027405 -0.695180  1.178948  0.908321  ...  0.078574  0.030638   \n173342   0.012862  0.115334  2.249141  0.863318  ...  0.274619  0.008551   \n805876   0.004499  0.033926  1.007645  0.774532  ...  0.184191  0.005097   \n1225798  0.011868  0.078575  0.669550  0.626528  ...  0.153664  0.015506   \n477303   0.004153  0.047083  0.894013  0.742597  ...  0.106789  0.008504   \n1669     0.010788  0.059227  2.410124  0.814387  ...  0.518946  0.007971   \n3602889  0.004323  0.041934  1.241417  0.886397  ...  0.134116  0.011124   \n429759   0.008350  0.072053  1.086191  0.826336  ...  0.153566  0.008760   \n4156     0.007244  0.070784  0.980858  0.733576  ...  0.126550  0.012397   \n384353   0.008384  0.090715  1.378512  0.904912  ...  0.137619  0.011073   \n2948423  0.005932  0.069471  1.627233  0.866078  ...  0.186740  0.008285   \n289739   0.008039  0.085481  1.052130  0.872661  ...  0.108986  0.006505   \n3824542 -0.004939 -0.027659  1.210300  0.819038  ...  0.469209  0.007213   \n1189993  0.005480  0.035799  1.151275  0.758562  ...  0.211251  0.023313   \n3217957  0.002352  0.024616  1.129151  0.853076  ...  0.124632  0.027548   \n190451   0.008337  0.080742  1.352792  0.882493  ...  0.150606  0.005720   \n1929247  0.004434  0.049491  1.934952  0.804748  ...  0.228262  0.008210   \n899642   0.008643  0.084952  1.365328  0.858913  ...  0.145646  0.005596   \n128258   0.001601  0.017294  2.400955  0.905151  ...  0.287490  0.004104   \n255547   0.008646  0.074092  1.202279  0.826663  ...  0.174019  0.009023   \n790703   0.003596  0.038429  0.739489  0.621548  ...  0.104297  0.006499   \n702836   0.002817  0.026981  1.409556  0.892636  ...  0.158126  0.005857   \n3351598 -0.040667 -3.194763  1.307669  0.979417  ...  0.056874  0.025144   \n954671   0.004563  0.054824  0.997973  0.788658  ...  0.098272  0.010608   \n489155   0.002829  0.035203  1.383521  0.911881  ...  0.131835  0.003241   \n183846   0.006742  0.039770  1.302602  0.790081  ...  0.271255  0.006824   \n\n         LLRGL-4Q  OEXTA-4Q   INCEMP-4Q    ROA-4Q    ROE-4Q   TDTL-4Q  \\\n487142   0.009076  0.022150   42.636364  0.010042  0.073789  1.382277   \n3593307  0.028888  0.014242   50.800000  0.003302  0.032095  0.966623   \n3134250  0.008618  0.037980    0.238095  0.000094  0.001140  0.786979   \n537355   0.015515  0.036625   15.731707  0.007077  0.074575  1.801381   \n307062   0.045195  0.025085  -50.659341 -0.011837 -0.100087  1.206137   \n3482894  0.018893  0.038533  -87.655172 -0.019009 -0.137517  0.997138   \n2078290  0.026230  0.028958   -4.026685 -0.000896 -0.006092  1.258679   \n518354   0.019214  0.055568    7.636364  0.004041  0.028316  1.232713   \n904667   0.010503  0.037885   28.938776  0.011279  0.149704  2.159065   \n613334   0.009503  0.023646   19.800000  0.005308  0.048529  1.541969   \n391418   0.017168  0.037993   11.921053  0.004617  0.026392  1.745434   \n349129   0.015760  0.030306   27.125000  0.011025  0.067197  1.696427   \n2140348  0.021233  0.026165  -57.617647 -0.011879 -0.170972  0.929250   \n117458   0.010229  0.024429   22.619718  0.006183  0.055673  1.096756   \n834979   0.023404  0.030443  -47.331839 -0.012507 -0.173391  0.966745   \n340144   0.017290  0.023852   28.153846  0.006034  0.065544  1.044889   \n2068107  0.035150  0.037553 -114.743590 -0.036445 -0.285486  1.224690   \n158947   0.011702  0.027492   38.741935  0.007820  0.059978  1.083530   \n122153   0.019244  0.026134   19.687500  0.004781  0.049739  3.597458   \n750154   0.010174  0.025798   43.916667  0.012843  0.167217  1.280753   \n722227   0.044322  0.069322  -32.882353 -0.019862 -0.336140  1.435610   \n6141     0.018994  0.024404   27.000000  0.006195  0.065246  2.008684   \n444677   0.000826  0.024176   23.833333  0.003956  0.038286  1.158019   \n2936840  0.016362  0.033372   -4.678571 -0.001485 -0.018589  1.447504   \n937759   0.011566  0.023198   50.687500  0.012169  0.116015  1.907283   \n803658   0.017293  0.022407   51.583333  0.011069  0.088227  1.577838   \n200435   0.019307  0.023984   50.774834  0.013238  0.173164  1.174067   \n719030   0.008481  0.028375   38.181818  0.008399  0.078038  1.388696   \n3548763  0.013321  0.036415  -31.360000 -0.007691 -0.059081  1.299218   \n3067929  0.060884  0.029688 -247.921053 -0.045397 -0.357330  1.180967   \n...           ...       ...         ...       ...       ...       ...   \n999935   0.026934  0.037992    3.110000  0.001173  0.010763  1.251351   \n412845   0.010764  0.022869   32.287671  0.008600  0.095471  1.630576   \n3623969  0.029560  0.031714   48.750000  0.013861  0.100257  1.564445   \n794345   0.027766  0.011665   53.571429  0.004372  0.032629  2.173636   \n895831   0.036518  0.036625 -208.646341 -0.039427 -0.598091  1.053491   \n173342   0.022750  0.023060   73.000000  0.014792  0.143306  2.324792   \n805876   0.007450  0.026974   19.000000  0.005991  0.047537  1.094636   \n1225798  0.016520  0.033370   35.000000  0.006392  0.044314  0.655194   \n477303   0.010837  0.030248   14.644068  0.004649  0.055475  0.896841   \n1669     0.024153  0.020969   52.152542  0.012546  0.073255  2.496510   \n3602889  0.014795  0.020256    8.631579  0.001215  0.012045  1.177830   \n429759   0.012703  0.034971   13.804348  0.004353  0.041100  1.268845   \n4156     0.017842  0.034520    5.176471  0.001719  0.019546  1.127239   \n384353   0.016314  0.034207   16.500000  0.007236  0.077465  1.332095   \n2948423  0.015080  0.027507   62.333333  0.012470  0.121537  1.622726   \n289739   0.007778  0.032341   29.976190  0.010905  0.119643  1.011890   \n3824542  0.011770  0.044154 -110.857143 -0.027643 -0.096129  1.159813   \n1189993  0.034304  0.028324  -21.289003 -0.003745 -0.026088  1.130386   \n3217957  0.034742  0.029404  -87.378378 -0.018810 -0.190333  1.069521   \n190451   0.008786  0.026679   28.000000  0.009199  0.093817  1.379471   \n1929247  0.019564  0.039259   21.180180  0.005338  0.055724  1.581081   \n899642   0.008629  0.030212   12.475410  0.003442  0.036450  1.305955   \n128258   0.013971  0.042059   -5.307692 -0.002598 -0.030762  3.109203   \n255547   0.013428  0.024831   48.000000  0.010072  0.086135  1.219444   \n790703   0.007791  0.029339   30.310345  0.006230  0.071603  0.754687   \n702836   0.008697  0.031258   13.612903  0.004603  0.043224  1.321418   \n3351598  0.033586  0.069404 -179.687500 -0.050375 -1.183128  1.263516   \n954671   0.013080  0.041345    7.936709  0.003326  0.041728  0.992302   \n489155   0.005535  0.029038    8.250000  0.002161  0.027990  1.568042   \n183846   0.011426  0.030643   26.473684  0.009104  0.056201  1.334068   \n\n          TDTA-4Q   TATA-4Q  \n487142   0.857678  0.258447  \n3593307  0.858089  0.000000  \n3134250  0.703121  0.039611  \n537355   0.881587  0.309527  \n307062   0.880024  0.095439  \n3482894  0.771170  0.131618  \n2078290  0.801821  0.193432  \n518354   0.842655  0.000120  \n904667   0.917247  0.000000  \n613334   0.887480  0.141689  \n391418   0.805051  0.455112  \n349129   0.832146  0.404583  \n2140348  0.706439  0.064555  \n117458   0.807066  0.083997  \n834979   0.787936  0.066190  \n340144   0.758275  0.175070  \n2068107  0.821750  0.000000  \n158947   0.775581  0.145845  \n122153   0.902204  0.216855  \n750154   0.917916  0.150121  \n722227   0.937962  0.191870  \n6141     0.902176  0.000000  \n444677   0.892122  0.000000  \n2936840  0.914865  0.210332  \n937759   0.890823  0.293507  \n803658   0.716278  0.385884  \n200435   0.864649  0.113722  \n719030   0.887318  0.239482  \n3548763  0.847699  0.264705  \n3067929  0.797291  0.079523  \n...           ...       ...  \n999935   0.867201  0.140521  \n412845   0.852289  0.393662  \n3623969  0.847684  0.000000  \n794345   0.808223  0.557049  \n895831   0.883854  0.073596  \n173342   0.873826  0.455495  \n805876   0.748956  0.186706  \n1225798  0.615012  0.000100  \n477303   0.703805  0.088539  \n1669     0.823894  0.147797  \n3602889  0.885625  0.118922  \n429759   0.875009  0.157995  \n4156     0.783229  0.176553  \n384353   0.904177  0.000000  \n2948423  0.891573  0.340877  \n289739   0.846227  0.054930  \n3824542  0.710802  0.158643  \n1189993  0.768207  0.231102  \n3217957  0.848057  0.125041  \n190451   0.898100  0.281662  \n1929247  0.663482  0.352342  \n899642   0.846825  0.240930  \n128258   0.913397  0.110438  \n255547   0.819428  0.212383  \n790703   0.629572  0.096865  \n702836   0.889823  0.063683  \n3351598  0.945910  0.068054  \n954671   0.804749  0.070803  \n489155   0.918156  0.000000  \n183846   0.796696  0.289001  \n\n[5513 rows x 55 columns]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-bff0a5bcbe8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#(https://medium.com/analytics-vidhya/introduction-to-neural-networks-for-finance-6abd5675e497)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    707\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         shuffle=shuffle)\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2543\u001b[0m             not tensor_util.is_tensor(x_input)):\n\u001b[1;32m   2544\u001b[0m           raise ValueError('Please provide as model inputs either a single '\n\u001b[0;32m-> 2545\u001b[0;31m                            'array or a list of arrays. You passed: x=' + str(x))\n\u001b[0m\u001b[1;32m   2546\u001b[0m         \u001b[0mall_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Please provide as model inputs either a single array or a list of arrays. You passed: x=             EQTA      EQTL     LLRTA     LLRGL     OEXTA      INCEMP  \\\n487142   0.135469  0.219712  0.004861  0.007883  0.015192   35.090909   \n3593307  0.092253  0.104042  0.036328  0.040970  0.012562   25.666667   \n3134250  0.082356  0.100571  0.008513  0.010396  0.036723    4.153846   \n537355   0.087692  0.207520  0.005452  0.012901  0.024309   10.622222   \n307062   0.127852  0.186926  0.027541  0.040266  0.021548    8.466667   \n3482894  0.128233  0.174938  0.013176  0.017974  0.026977  -11.821429   \n2078290  0.134291  0.227563  0.014798  0.025075  0.025034   16.555455   \n518354   0.148720  0.205192  0.012503  0.017251  0.052498    7.347826   \n904667   0.076193  0.176231  0.004657  0.010771  0.027759   17.541667   \n613334   0.108285  0.182628  0.005635  0.009504  0.016728   26.818182   \n391418   0.179367  0.398005  0.013135  0.029146  0.029504    5.166667   \n349129   0.162108  0.356917  0.007100  0.015632  0.019909   25.704545   \n2140348  0.074561  0.098370  0.013868  0.018296  0.019760   10.393939   \n117458   0.115381  0.168465  0.011076  0.016171  0.016834   24.054054   \n834979   0.055454  0.066917  0.019895  0.024007  0.023497  -61.342105   \n340144   0.099588  0.134056  0.013343  0.017962  0.019614   31.480000   \n2068107  0.139172  0.213593  0.025532  0.039184  0.034852  -39.657895   \n158947   0.126356  0.189798  0.008001  0.012019  0.018810   36.885246   \n122153   0.128872  0.414666  0.006031  0.019407  0.024545    6.941176   \n750154   0.077829  0.108996  0.008580  0.012016  0.018551   43.883333   \n722227   0.043545  0.061762  0.020988  0.029768  0.042536   -9.666667   \n6141     0.090484  0.202586  0.006494  0.014540  0.016302   26.090909   \n444677   0.106678  0.139776  0.001241  0.001626  0.019108   22.333333   \n2936840  0.093773  0.138799  0.017552  0.025981  0.030092   -6.625000   \n937759   0.126390  0.217976  0.006359  0.010967  0.020328   36.515152   \n803658   0.154279  0.260325  0.008834  0.014907  0.018338   42.666667   \n200435   0.093891  0.128525  0.012523  0.017142  0.019415   44.386667   \n719030   0.108328  0.181117  0.005800  0.009698  0.018258   43.100000   \n3548763  0.139389  0.217168  0.009648  0.015032  0.023446   17.000000   \n3067929  0.111422  0.147760  0.049365  0.065465  0.021013  -79.921053   \n...           ...       ...       ...       ...       ...         ...   \n999935   0.108819  0.165464  0.019108  0.029055  0.026945    0.466019   \n412845   0.092181  0.178049  0.005764  0.011134  0.015931   28.635135   \n3623969  0.135794  0.244630  0.015847  0.028548  0.026008   34.629630   \n794345   0.146918  0.418587  0.005396  0.015374  0.008319   51.000000   \n895831   0.039422  0.051168  0.037432  0.048585  0.028732 -130.747253   \n173342   0.111518  0.290531  0.009037  0.023542  0.016247   60.312500   \n805876   0.132621  0.172537  0.005226  0.006799  0.021379   14.341463   \n1225798  0.151043  0.161415  0.016558  0.017695  0.018774   67.181818   \n477303   0.088201  0.106185  0.006826  0.008218  0.023050   13.271930   \n1669     0.182143  0.539039  0.008249  0.024414  0.014856   47.122807   \n3602889  0.103090  0.144379  0.011877  0.016633  0.015670   31.095238   \n429759   0.115882  0.152323  0.008917  0.011721  0.028019   25.063830   \n4156     0.102335  0.136832  0.011378  0.015214  0.024893   22.983051   \n384353   0.092425  0.140796  0.009963  0.015177  0.025054   21.250000   \n2948423  0.085382  0.160420  0.009637  0.018107  0.019580   32.076923   \n289739   0.094039  0.113379  0.007408  0.008932  0.023780   22.837209   \n3824542  0.178554  0.263851  0.008153  0.012047  0.022823  -29.400000   \n1189993  0.153063  0.232305  0.023306  0.035372  0.019617   35.135542   \n3217957  0.095562  0.126489  0.026261  0.034759  0.021369    9.106383   \n190451   0.103257  0.158285  0.006139  0.009411  0.020435   26.453333   \n1929247  0.089601  0.215439  0.006852  0.016476  0.034269   15.038356   \n899642   0.101737  0.161720  0.007851  0.012479  0.022150   31.322581   \n128258   0.092568  0.245541  0.004122  0.010934  0.033177    3.076923   \n255547   0.116696  0.169720  0.009417  0.013696  0.018711   41.866667   \n790703   0.093573  0.111329  0.008866  0.010548  0.021677   17.333333   \n702836   0.104390  0.164841  0.007787  0.012297  0.022364    8.645161   \n3351598  0.012729  0.016995  0.012958  0.017301  0.053146 -130.133333   \n954671   0.083234  0.105325  0.010639  0.013462  0.030926   10.825000   \n489155   0.080357  0.121918  0.003092  0.004691  0.021610   10.750000   \n183846   0.169514  0.279477  0.007186  0.011847  0.023957   20.589041   \n\n              ROA       ROE      TDTL      TDTA  ...   EQTL-4Q  LLRTA-4Q  \\\n487142   0.007850  0.057949  1.390573  0.857393  ...  0.219331  0.005631   \n3593307  0.003842  0.041644  0.980606  0.869490  ...  0.115903  0.025644   \n3134250  0.001654  0.020079  0.934364  0.765143  ...  0.092728  0.007699   \n537355   0.004365  0.049776  2.102950  0.888647  ...  0.193911  0.007593   \n307062   0.002068  0.016177  1.270097  0.868712  ...  0.162100  0.032975   \n3482894 -0.002327 -0.018148  1.078908  0.790864  ...  0.178732  0.014612   \n2078290  0.004292  0.031960  1.384858  0.817240  ...  0.230841  0.016710   \n518354   0.004119  0.027696  1.135113  0.822715  ...  0.208783  0.013134   \n904667   0.006657  0.087372  2.125357  0.918890  ...  0.177338  0.004462   \n613334   0.007488  0.069151  1.498138  0.888288  ...  0.190050  0.005469   \n391418   0.002075  0.011569  1.759689  0.793029  ...  0.379252  0.007919   \n349129   0.008588  0.052977  1.835794  0.833799  ...  0.334473  0.007731   \n2140348  0.002048  0.027462  1.043680  0.791079  ...  0.091393  0.016142   \n117458   0.006699  0.058058  1.177048  0.806153  ...  0.150928  0.007527   \n834979  -0.016508 -0.297695  0.929028  0.769886  ...  0.088498  0.019076   \n340144   0.006562  0.065896  1.017093  0.755581  ...  0.126852  0.012547   \n2068107 -0.013771 -0.098949  1.307066  0.851654  ...  0.190256  0.023585   \n158947   0.006771  0.053584  1.228648  0.817956  ...  0.182142  0.008376   \n122153   0.002252  0.017476  2.777437  0.863188  ...  0.383238  0.004826   \n750154   0.012172  0.156391  1.286908  0.918917  ...  0.107165  0.007292   \n722227  -0.004876 -0.111969  1.352172  0.953344  ...  0.090439  0.028958   \n6141     0.005434  0.060054  2.029462  0.906449  ...  0.211396  0.008531   \n444677   0.003695  0.034634  1.165282  0.889351  ...  0.134106  0.000636   \n2936840 -0.002172 -0.023161  1.337444  0.903577  ...  0.126431  0.010341   \n937759   0.010468  0.082824  1.492913  0.865644  ...  0.224580  0.005402   \n803658   0.010374  0.067245  1.407891  0.834373  ...  0.276373  0.007850   \n200435   0.011942  0.127185  1.202771  0.878662  ...  0.103804  0.014219   \n719030   0.007862  0.072571  1.476289  0.882989  ...  0.168435  0.005419   \n3548763  0.004286  0.030748  1.306679  0.838687  ...  0.199519  0.008692   \n3067929 -0.014474 -0.129903  0.951739  0.717682  ...  0.188183  0.041104   \n...           ...       ...       ...       ...  ...       ...       ...   \n999935   0.000179  0.001648  1.319114  0.867532  ...  0.157289  0.018666   \n412845   0.007271  0.078873  1.702123  0.881238  ...  0.172329  0.005626   \n3623969  0.010698  0.078783  1.525457  0.846780  ...  0.255154  0.016017   \n794345   0.004215  0.028692  2.310042  0.810792  ...  0.360378  0.010324   \n895831  -0.027405 -0.695180  1.178948  0.908321  ...  0.078574  0.030638   \n173342   0.012862  0.115334  2.249141  0.863318  ...  0.274619  0.008551   \n805876   0.004499  0.033926  1.007645  0.774532  ...  0.184191  0.005097   \n1225798  0.011868  0.078575  0.669550  0.626528  ...  0.153664  0.015506   \n477303   0.004153  0.047083  0.894013  0.742597  ...  0.106789  0.008504   \n1669     0.010788  0.059227  2.410124  0.814387  ...  0.518946  0.007971   \n3602889  0.004323  0.041934  1.241417  0.886397  ...  0.134116  0.011124   \n429759   0.008350  0.072053  1.086191  0.826336  ...  0.153566  0.008760   \n4156     0.007244  0.070784  0.980858  0.733576  ...  0.126550  0.012397   \n384353   0.008384  0.090715  1.378512  0.904912  ...  0.137619  0.011073   \n2948423  0.005932  0.069471  1.627233  0.866078  ...  0.186740  0.008285   \n289739   0.008039  0.085481  1.052130  0.872661  ...  0.108986  0.006505   \n3824542 -0.004939 -0.027659  1.210300  0.819038  ...  0.469209  0.007213   \n1189993  0.005480  0.035799  1.151275  0.758562  ...  0.211251  0.023313   \n3217957  0.002352  0.024616  1.129151  0.853076  ...  0.124632  0.027548   \n190451   0.008337  0.080742  1.352792  0.882493  ...  0.150606  0.005720   \n1929247  0.004434  0.049491  1.934952  0.804748  ...  0.228262  0.008210   \n899642   0.008643  0.084952  1.365328  0.858913  ...  0.145646  0.005596   \n128258   0.001601  0.017294  2.400955  0.905151  ...  0.287490  0.004104   \n255547   0.008646  0.074092  1.202279  0.826663  ...  0.174019  0.009023   \n790703   0.003596  0.038429  0.739489  0.621548  ...  0.104297  0.006499   \n702836   0.002817  0.026981  1.409556  0.892636  ...  0.158126  0.005857   \n3351598 -0.040667 -3.194763  1.307669  0.979417  ...  0.056874  0.025144   \n954671   0.004563  0.054824  0.997973  0.788658  ...  0.098272  0.010608   \n489155   0.002829  0.035203  1.383521  0.911881  ...  0.131835  0.003241   \n183846   0.006742  0.039770  1.302602  0.790081  ...  0.271255  0.006824   \n\n         LLRGL-4Q  OEXTA-4Q   INCEMP-4Q    ROA-4Q    ROE-4Q   TDTL-4Q  \\\n487142   0.009076  0.022150   42.636364  0.010042  0.073789  1.382277   \n3593307  0.028888  0.014242   50.800000  0.003302  0.032095  0.966623   \n3134250  0.008618  0.037980    0.238095  0.000094  0.001140  0.786979   \n537355   0.015515  0.036625   15.731707  0.007077  0.074575  1.801381   \n307062   0.045195  0.025085  -50.659341 -0.011837 -0.100087  1.206137   \n3482894  0.018893  0.038533  -87.655172 -0.019009 -0.137517  0.997138   \n2078290  0.026230  0.028958   -4.026685 -0.000896 -0.006092  1.258679   \n518354   0.019214  0.055568    7.636364  0.004041  0.028316  1.232713   \n904667   0.010503  0.037885   28.938776  0.011279  0.149704  2.159065   \n613334   0.009503  0.023646   19.800000  0.005308  0.048529  1.541969   \n391418   0.017168  0.037993   11.921053  0.004617  0.026392  1.745434   \n349129   0.015760  0.030306   27.125000  0.011025  0.067197  1.696427   \n2140348  0.021233  0.026165  -57.617647 -0.011879 -0.170972  0.929250   \n117458   0.010229  0.024429   22.619718  0.006183  0.055673  1.096756   \n834979   0.023404  0.030443  -47.331839 -0.012507 -0.173391  0.966745   \n340144   0.017290  0.023852   28.153846  0.006034  0.065544  1.044889   \n2068107  0.035150  0.037553 -114.743590 -0.036445 -0.285486  1.224690   \n158947   0.011702  0.027492   38.741935  0.007820  0.059978  1.083530   \n122153   0.019244  0.026134   19.687500  0.004781  0.049739  3.597458   \n750154   0.010174  0.025798   43.916667  0.012843  0.167217  1.280753   \n722227   0.044322  0.069322  -32.882353 -0.019862 -0.336140  1.435610   \n6141     0.018994  0.024404   27.000000  0.006195  0.065246  2.008684   \n444677   0.000826  0.024176   23.833333  0.003956  0.038286  1.158019   \n2936840  0.016362  0.033372   -4.678571 -0.001485 -0.018589  1.447504   \n937759   0.011566  0.023198   50.687500  0.012169  0.116015  1.907283   \n803658   0.017293  0.022407   51.583333  0.011069  0.088227  1.577838   \n200435   0.019307  0.023984   50.774834  0.013238  0.173164  1.174067   \n719030   0.008481  0.028375   38.181818  0.008399  0.078038  1.388696   \n3548763  0.013321  0.036415  -31.360000 -0.007691 -0.059081  1.299218   \n3067929  0.060884  0.029688 -247.921053 -0.045397 -0.357330  1.180967   \n...           ...       ...         ...       ...       ...       ...   \n999935   0.026934  0.037992    3.110000  0.001173  0.010763  1.251351   \n412845   0.010764  0.022869   32.287671  0.008600  0.095471  1.630576   \n3623969  0.029560  0.031714   48.750000  0.013861  0.100257  1.564445   \n794345   0.027766  0.011665   53.571429  0.004372  0.032629  2.173636   \n895831   0.036518  0.036625 -208.646341 -0.039427 -0.598091  1.053491   \n173342   0.022750  0.023060   73.000000  0.014792  0.143306  2.324792   \n805876   0.007450  0.026974   19.000000  0.005991  0.047537  1.094636   \n1225798  0.016520  0.033370   35.000000  0.006392  0.044314  0.655194   \n477303   0.010837  0.030248   14.644068  0.004649  0.055475  0.896841   \n1669     0.024153  0.020969   52.152542  0.012546  0.073255  2.496510   \n3602889  0.014795  0.020256    8.631579  0.001215  0.012045  1.177830   \n429759   0.012703  0.034971   13.804348  0.004353  0.041100  1.268845   \n4156     0.017842  0.034520    5.176471  0.001719  0.019546  1.127239   \n384353   0.016314  0.034207   16.500000  0.007236  0.077465  1.332095   \n2948423  0.015080  0.027507   62.333333  0.012470  0.121537  1.622726   \n289739   0.007778  0.032341   29.976190  0.010905  0.119643  1.011890   \n3824542  0.011770  0.044154 -110.857143 -0.027643 -0.096129  1.159813   \n1189993  0.034304  0.028324  -21.289003 -0.003745 -0.026088  1.130386   \n3217957  0.034742  0.029404  -87.378378 -0.018810 -0.190333  1.069521   \n190451   0.008786  0.026679   28.000000  0.009199  0.093817  1.379471   \n1929247  0.019564  0.039259   21.180180  0.005338  0.055724  1.581081   \n899642   0.008629  0.030212   12.475410  0.003442  0.036450  1.305955   \n128258   0.013971  0.042059   -5.307692 -0.002598 -0.030762  3.109203   \n255547   0.013428  0.024831   48.000000  0.010072  0.086135  1.219444   \n790703   0.007791  0.029339   30.310345  0.006230  0.071603  0.754687   \n702836   0.008697  0.031258   13.612903  0.004603  0.043224  1.321418   \n3351598  0.033586  0.069404 -179.687500 -0.050375 -1.183128  1.263516   \n954671   0.013080  0.041345    7.936709  0.003326  0.041728  0.992302   \n489155   0.005535  0.029038    8.250000  0.002161  0.027990  1.568042   \n183846   0.011426  0.030643   26.473684  0.009104  0.056201  1.334068   \n\n          TDTA-4Q   TATA-4Q  \n487142   0.857678  0.258447  \n3593307  0.858089  0.000000  \n3134250  0.703121  0.039611  \n537355   0.881587  0.309527  \n307062   0.880024  0.095439  \n3482894  0.771170  0.131618  \n2078290  0.801821  0.193432  \n518354   0.842655  0.000120  \n904667   0.917247  0.000000  \n613334   0.887480  0.141689  \n391418   0.805051  0.455112  \n349129   0.832146  0.404583  \n2140348  0.706439  0.064555  \n117458   0.807066  0.083997  \n834979   0.787936  0.066190  \n340144   0.758275  0.175070  \n2068107  0.821750  0.000000  \n158947   0.775581  0.145845  \n122153   0.902204  0.216855  \n750154   0.917916  0.150121  \n722227   0.937962  0.191870  \n6141     0.902176  0.000000  \n444677   0.892122  0.000000  \n2936840  0.914865  0.210332  \n937759   0.890823  0.293507  \n803658   0.716278  0.385884  \n200435   0.864649  0.113722  \n719030   0.887318  0.239482  \n3548763  0.847699  0.264705  \n3067929  0.797291  0.079523  \n...           ...       ...  \n999935   0.867201  0.140521  \n412845   0.852289  0.393662  \n3623969  0.847684  0.000000  \n794345   0.808223  0.557049  \n895831   0.883854  0.073596  \n173342   0.873826  0.455495  \n805876   0.748956  0.186706  \n1225798  0.615012  0.000100  \n477303   0.703805  0.088539  \n1669     0.823894  0.147797  \n3602889  0.885625  0.118922  \n429759   0.875009  0.157995  \n4156     0.783229  0.176553  \n384353   0.904177  0.000000  \n2948423  0.891573  0.340877  \n289739   0.846227  0.054930  \n3824542  0.710802  0.158643  \n1189993  0.768207  0.231102  \n3217957  0.848057  0.125041  \n190451   0.898100  0.281662  \n1929247  0.663482  0.352342  \n899642   0.846825  0.240930  \n128258   0.913397  0.110438  \n255547   0.819428  0.212383  \n790703   0.629572  0.096865  \n702836   0.889823  0.063683  \n3351598  0.945910  0.068054  \n954671   0.804749  0.070803  \n489155   0.918156  0.000000  \n183846   0.796696  0.289001  \n\n[5513 rows x 55 columns]"
     ]
    }
   ],
   "source": [
    "# Multilayer Perceptron (MLP) \n",
    "# source: https://medium.com/engineer-quant/multilayer-perceptron-4453615c4337\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(10, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(10, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(1, activation=tf.nn.relu))\n",
    "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "\n",
    "# Adam optimizer is gaining popularity in the machine learning community because it is \n",
    "#a more efficient algorithm to optimize compared to traditional stochastic gradient descent. \n",
    "#The advantages are best understood by looking at  the advantages of two other extensions of\n",
    "#stochastic gradient descent \n",
    "#(https://medium.com/analytics-vidhya/introduction-to-neural-networks-for-finance-6abd5675e497)\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10)\n",
    "model.evaluate(X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Long Short Term Model (LSTM)\n",
    "# source: https://www.altumintelligence.com/articles/a/Time-Series-Prediction-Using-LSTM-Deep-Neural-Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# break up the data into training sets\n",
    "def gen_train(self, seq_len):\n",
    "    \"\"\"\n",
    "    Generates training data\n",
    "    :param seq_len: length of window\n",
    "    :return: X_train and Y_train\n",
    "    \"\"\"\n",
    "    for i in range((len(self.stock_train)//seq_len)*seq_len - seq_len - 1):\n",
    "        x = np.array(self.stock_train.iloc[i: i + seq_len, 1])\n",
    "        y = np.array([self.stock_train.iloc[i + seq_len + 1, 1]], np.float64)\n",
    "        self.input_train.append(x)\n",
    "        self.output_train.append(y)\n",
    "    self.X_train = np.array(self.input_train)\n",
    "    self.Y_train = np.array(self.output_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected lstm_input to have 3 dimensions, but got array with shape (5513, 55)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-2dcd096a5d47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mean_squared_error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    707\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         shuffle=shuffle)\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2649\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2651\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2653\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    374\u001b[0m                            \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected lstm_input to have 3 dimensions, but got array with shape (5513, 55)"
     ]
    }
   ],
   "source": [
    "# Long Short Term Model (LSTM)\n",
    "# source: https://www.altumintelligence.com/articles/a/Time-Series-Prediction-Using-LSTM-Deep-Neural-Networks\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.LSTM(20, input_shape=(10, 1), return_sequences=True))\n",
    "model.add(tf.keras.layers.LSTM(20))\n",
    "model.add(tf.keras.layers.Dense(1, activation=tf.nn.relu))\n",
    "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "model.fit(X_train, y_train, epochs=20)\n",
    "\n",
    "model.evaluate(X_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note on Backtesting - check how to do it?\n",
    "\n",
    "#Example below. For full blown backtest systems, you will need to consider factors such as \n",
    "#survivorship bias, look ahead bias, market regime change and transaction costs.\n",
    "\n",
    "#Now that we have fitted our models using our training data and evaluated it using our test data, \n",
    "#we can take the assessment a step further by backtesting the model on new data. Backtesting is \n",
    "#essentially running your strategy (or i our case, the prediction algorithm) over data from a period \n",
    "#of time to see the profit and loss, or accuracy of the algorithm. This is done simply by\n",
    "\n",
    "def back_test(strategy, seq_len, ticker, start_date, end_date, dim):\n",
    "    \"\"\"\n",
    "    A simple back test for a given date period\n",
    "    :param strategy: the chosen strategy. Note to have already formed the model, and fitted with training data.\n",
    "    :param seq_len: length of the days used for prediction\n",
    "    :param ticker: company ticker\n",
    "    :param start_date: starting date\n",
    "    :type start_date: \"YYYY-mm-dd\"\n",
    "    :param end_date: ending date\n",
    "    :type end_date: \"YYYY-mm-dd\"\n",
    "    :param dim: dimension required for strategy: 3dim for LSTM and 2dim for MLP\n",
    "    :type dim: tuple\n",
    "    :return: Percentage errors array that gives the errors for every test in the given date range\n",
    "    \"\"\"\n",
    "    data = pdr.get_data_yahoo(ticker, start_date, end_date)\n",
    "    stock_data = data[\"Adj Close\"]\n",
    "    errors = []\n",
    "    for i in range((len(stock_data)//10)*10 - seq_len - 1):\n",
    "        x = np.array(stock_data.iloc[i: i + seq_len, 1]).reshape(dim) / 200\n",
    "        y = np.array(stock_data.iloc[i + seq_len + 1, 1]) / 200\n",
    "        predict = strategy.predict(x)\n",
    "        while predict == 0:\n",
    "            predict = strategy.predict(x)\n",
    "        error = (predict - y) / 100\n",
    "        errors.append(error)\n",
    "        total_error = np.array(errors)\n",
    "    print(f\"Average error = {total_error.mean()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
